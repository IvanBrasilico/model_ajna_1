{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Project - combining geometric and semantic distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Proposal\n",
    "\n",
    "Ivan da Silva Bras√≠lico\n",
    "\n",
    "April 23, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Background\n",
    "\n",
    "There are many aproachs for adressing image similarity search. The old ones use hand crafted features, like HOG, SIFT or Histograms of images, and some distance, like Euclidean Distances, to compare these features. More modern aproaches uses Neural Networks.\n",
    "\n",
    "Two common neural net image similarity search methods are using autoencoders to generate a compact representation of the image, or accessing this compact representation on features learned on Vanilla Networks pre-trained on ImageNet (i.e., using values from the latter convolutional filters on pre-trained Nets like VGG, DenseNet, Inception, etc). The autoencoder method tends to learn the geometric/exact match. The convolutional filter can, depending on the layer used, be more geometric or more semantic. These methods commonly use euclidean distances to compare the generated features between target images and the image database.\n",
    "\n",
    "There are alternative aproachs, like, for fast search, as proposed by Hinton, using Markov Models to learn binary patches and use hamming distance, or even memory addresses, for very fast searching (https://pdfs.semanticscholar.org/bba0/6d9f6632391313f62143596342945cbf7a0e.pdf). Also, one can generate text labels for images (image captioning https://arxiv.org/pdf/1810.04020.pdf) and use text retrieval methods (bag of words, tf/idf) to do semantic similarity search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "All the cited methods have their strenghts, but for the problem that I have in mind, I feel like that I need a different method. I have greyscale Container Cargo X-Ray Images, and these pre-trained models are trained with color photographs, very different images from what we see in papers and contests on the Internet and open courses. Also, **I need a search that can capture a set of characteristics: semantic, geometry, packing, density zones, patterns, and is position invariant and translation invariant**. Also, I have some images that are very similar, but not equal, like the same cargo (HS Code) but with different quantity, size or qualities.\n",
    "\n",
    "Then, I need some method that trains comparing an image with itself (like in autoencoders and hinton deep belief markov models), with its semantic (like in convolutional networks used to object detection and classification), and with its \"cousins\", images that are not equal but have the same cargo (like siamese models trained to classify mnist and fashion-mnist).\n",
    "\n",
    "Clarifying, I need a similarity search that, when there is a seizure, allows the fiscalization agents that are in cargo of X-ray container scanners to use the image of the problematic cargo to find other cargo that have the same menace (like a smugling, or even drugs/guns ocultation). Or may find anomalies in a lot, that was expected to be very similar. I am already using a simple linear autoencoder AND with that \n",
    "\n",
    "But these images are private, and the rules of Udacity says that I need a public dataset. So I looked for a public dataset that has some similarity with cargo XRay domain. The public datasets that looked more similar with my task are the chest XRay public datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "\n",
    "I will examine public Chest XRay datasets to see what fits more in my needs.\n",
    "\n",
    "https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "\n",
    "https://stanfordmlgroup.github.io/projects/chexnet/\n",
    "\n",
    "https://www.kaggle.com/nih-chest-xrays/data/metadata\n",
    "\n",
    "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "\n",
    "I have about 1.5 million X-Ray images, half in VGA, half in SVGA resolution. All of these were associated, by a script, with the Bill of Lading related information, that contains some information, like description of goods contained, weight, volume, HS Code, and others. Also, quite a few (only hundreds) are manually rotulated because there was a seizure (smuggling, cocaine, others). Once I can design a model that can do well on chest X-Ray, I will evaluate that on my database two.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "Using Siamese convolutuional netwoks, try to create an image similarity search engine that can do well on:\n",
    "\n",
    "* Detecting images from same disease/lot/HS Code (classify)\n",
    "* Detecting lot anomalies (unsimilarity larger than a threshold on same label)\n",
    "* Finding images similar to a patient case/cargo seized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "I already have a very simple full conected autoencoder on production. This model will be the baseline for the similarity search. \n",
    "\n",
    "Also, I will pick a vanilla convolutional network from keras.application to be the baseline of the classification test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "The classification task will be evaluated by checking accuracy, recall, precision, confusion matrix and f1-score and comparing it to other models.\n",
    "\n",
    "\n",
    "For the search task, the metrics are more dificult to set. I will take the last layer of the trained network and use this layer to give me a \"hash\" and calculate the euclidean distance between this hash and all other hashes of all images and sort then by this distance.\n",
    "\n",
    "The simpler evaluation metric could be the mean between all distances calculated on images of same label.\n",
    "\n",
    "Another evaluation metric will be comparing with the baseline autoencoder results.\n",
    "\n",
    "One evaluation for similarity search will need to use human avaliation, like on Information Retrieval. I think in randomic choosing some images, the searcher will exibit the 10 first results and an human evaluator will give some grade (between 0 to 100 or alternatively binary), that will be multiplied by the rank position, using precision at K. https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Design\n",
    "\n",
    "The project has two phases: phase one is for test and evaluation with the public dataset and this will be the submitted one. Phase two will take place after submition to Udacity.\n",
    "\n",
    "The simplified project design is:\n",
    "\n",
    "- Download the chest XRay dataset\n",
    "- Explore the dataset:\n",
    "    - Count the class examples\n",
    "    - Sample the classs examples (visualize)\n",
    "    - Extract some statistics, look for problems/incosistencies on data\n",
    "- Choose a model from keras.applications or from online kernels on problem\n",
    "- Train this as the baseline. Save the metrics.\n",
    "- Search for articles on the problem set and resume the findings\n",
    "- Choose a simple architecture for the siamese network (maybe the same for the previous problem)\n",
    "- Train and compare to baseline\n",
    "- Tune the hyperparameters\n",
    "- Once the hyperparameters are tuned, depending on the results of the evaluation metrics, change/expand the network architeture\n",
    "- Tune the hyperparameters again if the network is changed\n",
    "- Design the search task\n",
    "- Evaluate the search task\n",
    "  - The features extracted on last layers can than be reduced via PCA or T-SNE and visualized\n",
    "  - Also, they can be used to create an Index for image search, and that index can be visually evaluated and compared with baseline model\n",
    "\n",
    "\n",
    "Then, a script will be designed to generate a copy of cargo the images on disk, in series of folders named on HSCode. These folders will be inspected (first by the autoencoder and then visually) to see if the images on folder really have similarity. \n",
    "\n",
    "The same procedure aplied to chest X-Ray will be tried on this dataset also.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padma-venv",
   "language": "python",
   "name": "padma-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
