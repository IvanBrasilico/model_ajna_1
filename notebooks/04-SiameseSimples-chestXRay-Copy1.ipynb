{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR = '../models/siamese'\n",
    "LOG_DIR = '../logs/04chest_2/'\n",
    "SIZE = (224, 224)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "caminho_bases = os.path.join('..', 'bases', 'chest_xray')\n",
    "caminho_train = os.path.join(caminho_bases, 'train')\n",
    "caminho_test = os.path.join(caminho_bases, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, \\\n",
    "    ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "tensorboard_logs = TensorBoard(log_dir=LOG_DIR, histogram_freq=1,\n",
    "                               write_graph=False, write_images=False,\n",
    "                               update_freq='epoch')\n",
    "mcp_save = ModelCheckpoint(os.path.join(MODEL_DIR, \n",
    "                                        '04modelweights-loss.{epoch:02d}-{loss:.2f}.hdf5'),\n",
    "                           save_best_only=True, monitor='loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "=================================================================\n",
      "Total params: 1,529,888\n",
      "Trainable params: 1,529,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Conv2D, \\\n",
    "    BatchNormalization, concatenate, Dense, Dropout, Flatten, Input, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "SIZE = (224, 224)\n",
    "\n",
    "\n",
    "nuclear_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                         padding='same',\n",
    "                         activation='relu',\n",
    "                         input_shape=(*SIZE, 1)),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(256, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(256, (3, 3), activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    " \n",
    "])\n",
    "\n",
    "nuclear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Similarity_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          1529888     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features (Concatenate)    (None, 256)          0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           8224        merge_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,538,273\n",
      "Trainable params: 1,538,209\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a_in = Input(shape=(*SIZE, 1))\n",
    "b_in = Input(shape=(*SIZE, 1))\n",
    "\n",
    "a_feat = nuclear_model(a_in)\n",
    "b_feat = nuclear_model(b_in)\n",
    "\n",
    "combined_features = concatenate([a_feat, b_feat], name = 'merge_features')\n",
    "combined_features = Dense(32, activation = 'linear')(combined_features)\n",
    "# combined_features = Dropout(0.2)(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "# combined_features = Dense(32, activation = 'relu')(combined_features)\n",
    "# combined_features = Dropout(0.2)(combined_features)\n",
    "# combined_features = BatchNormalization()(combined_features)\n",
    "# combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = tf.keras.Model(inputs = [a_in, b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()\n",
    "\n",
    "similarity_model.compile(optimizer=RMSprop(lr=0.001), loss = 'binary_crossentropy', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_normal_train = os.path.join(caminho_train, 'NORMAL')\n",
    "caminho_pneumonia_train = os.path.join(caminho_train, 'PNEUMONIA')\n",
    "caminho_normal_test = os.path.join(caminho_test, 'NORMAL')\n",
    "caminho_pneumonia_test = os.path.join(caminho_test, 'PNEUMONIA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def generate_random_batch(nvazios_list, vazios_list, batch_size=64):\n",
    "    def get_item(classe):\n",
    "        if classe == 0:\n",
    "            return nvazios_list.pop()\n",
    "        return vazios_list.pop()\n",
    "    result = []\n",
    "    for i in range(batch_size):\n",
    "        classe1 = random.randint(0, 1)\n",
    "        item1 = get_item(classe1) \n",
    "        classe2 = random.randint(0, 1)\n",
    "        item2 = get_item(classe2)\n",
    "        if classe1 == classe2:\n",
    "            if item1 == item2:\n",
    "                alpha = 0\n",
    "            else:\n",
    "                alpha = 0.001\n",
    "        else:\n",
    "            alpha = 1\n",
    "        result.append((item1, item2, alpha))\n",
    "    return result  \n",
    "\n",
    "def image_generator(caminho1, caminho2, batch_size=64):\n",
    "    list_files1 = [filename for filename in os.listdir(caminho1)\n",
    "                   if filename[-4:] in  ['.jpg', 'jpeg', '.png']]\n",
    "    list_files2 = [filename for filename in os.listdir(caminho2)\n",
    "                   if filename[-4:] in  ['.jpg', 'jpeg', '.png']]\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    while True:\n",
    "        # Ciclar lista (se acabar, recarregar do come√ßo)\n",
    "        if len(list1) < batch_size * 2:\n",
    "            random.shuffle(list_files1)\n",
    "            list1 = [os.path.join(caminho1, arq) for arq in list_files1]\n",
    "        if len(list2) < batch_size * 2:\n",
    "            random.shuffle(list_files2)\n",
    "            list2 = [os.path.join(caminho2, arq) for arq in list_files2]\n",
    "        # Gerar um batch da lista\n",
    "        triples = generate_random_batch(list1, list2, batch_size)\n",
    "        X1 = np.zeros((batch_size, *SIZE, 1))\n",
    "        X2 = np.zeros((batch_size, *SIZE, 1))\n",
    "        y = np.zeros((batch_size, 1))\n",
    "        for ind, triple in enumerate(triples):\n",
    "            pil_img1 = Image.open(triple[0]).convert('L')\n",
    "            # print(pil_img1.size)\n",
    "            # print(pil_img1.mode)\n",
    "            # print(pil_img1.getbands())\n",
    "            pil_img1 = pil_img1.resize(SIZE, Image.ANTIALIAS)\n",
    "            pil_img2 = Image.open(triple[1]).convert('L')\n",
    "            pil_img2 = pil_img2.resize(SIZE, Image.ANTIALIAS)\n",
    "            label = triple[2]\n",
    "            X1[ind, :, :, 0] = np.array(pil_img1) / 255.\n",
    "            X2[ind, :, :, 0] = np.array(pil_img2) / 255.\n",
    "            y[ind, :] = label\n",
    "        \n",
    "        yield [X1, X2], y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = image_generator(caminho_normal_train, caminho_pneumonia_train)\n",
    "validation_generator = image_generator(caminho_normal_test, caminho_pneumonia_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch = 2\n",
    "val_loss = 0.69\n",
    "\n",
    "similarity_model.load_weights(os.path.join(\n",
    "    MODEL_DIR, \n",
    "    '04modelweights-loss.{:02d}-{:.2f}.hdf5'.format(epoch, val_loss)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 10:49:46.921875 140045613893376 deprecation.py:323] From /home/ivan/pybr/projeto/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 88s 4s/step - loss: 0.7275 - mae: 0.4982 - val_loss: 0.6953 - val_mae: 0.5000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 72s 4s/step - loss: 0.7056 - mae: 0.5006 - val_loss: 0.7075 - val_mae: 0.5039\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.5668 - mae: 0.4084 - val_loss: 1.5181 - val_mae: 0.4995\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 72s 4s/step - loss: 0.5002 - mae: 0.3443 - val_loss: 0.8880 - val_mae: 0.5186\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 71s 4s/step - loss: 0.4225 - mae: 0.2995 - val_loss: 0.7526 - val_mae: 0.5062\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: 0.3269 - mae: 0.2443 - val_loss: 0.7225 - val_mae: 0.4816\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.2934 - mae: 0.2225 - val_loss: 1.0923 - val_mae: 0.4957\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 72s 4s/step - loss: 0.2634 - mae: 0.2004 - val_loss: 0.7905 - val_mae: 0.4554\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.2573 - mae: 0.1912 - val_loss: 0.6853 - val_mae: 0.4253\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.2342 - mae: 0.1749 - val_loss: 1.0087 - val_mae: 0.4979\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.2103 - mae: 0.1617 - val_loss: 0.8999 - val_mae: 0.4422\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: 0.1885 - mae: 0.1455 - val_loss: 0.9617 - val_mae: 0.4648\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: 0.1932 - mae: 0.1439 - val_loss: 1.0038 - val_mae: 0.4463\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.1705 - mae: 0.1308 - val_loss: 1.3787 - val_mae: 0.5089\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.1644 - mae: 0.1256 - val_loss: 0.9092 - val_mae: 0.3932\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.1454 - mae: 0.1098 - val_loss: 0.7930 - val_mae: 0.3923\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.1577 - mae: 0.1171 - val_loss: 1.2064 - val_mae: 0.4187\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: 0.1378 - mae: 0.1010 - val_loss: 1.2632 - val_mae: 0.4497\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.1263 - mae: 0.0970 - val_loss: 0.6854 - val_mae: 0.3398\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.1320 - mae: 0.0976 - val_loss: 1.7645 - val_mae: 0.5050\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: 0.1186 - mae: 0.0873 - val_loss: 0.9415 - val_mae: 0.4134\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.1150 - mae: 0.0857 - val_loss: 1.4636 - val_mae: 0.4861\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 101s 5s/step - loss: 0.1073 - mae: 0.0805 - val_loss: 0.7159 - val_mae: 0.3413\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0981 - mae: 0.0731 - val_loss: 1.6339 - val_mae: 0.4384\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.1063 - mae: 0.0749 - val_loss: 1.4467 - val_mae: 0.4670\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0895 - mae: 0.0658 - val_loss: 1.1468 - val_mae: 0.4048\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: 0.0852 - mae: 0.0613 - val_loss: 1.1733 - val_mae: 0.4146\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0991 - mae: 0.0687 - val_loss: 1.2489 - val_mae: 0.4174\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0728 - mae: 0.0517 - val_loss: 1.1480 - val_mae: 0.4110\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0768 - mae: 0.0559 - val_loss: 1.1949 - val_mae: 0.4406\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: 0.0713 - mae: 0.0516 - val_loss: 1.5323 - val_mae: 0.4725\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: 0.0686 - mae: 0.0499 - val_loss: 0.5355 - val_mae: 0.2330\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: 0.0582 - mae: 0.0450 - val_loss: 1.3954 - val_mae: 0.4659\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: 0.0589 - mae: 0.0417 - val_loss: 1.1650 - val_mae: 0.4091\n",
      "Epoch 35/100\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 0.0817 - mae: 0.0520\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "20/20 [==============================] - 72s 4s/step - loss: 0.0830 - mae: 0.0526 - val_loss: 1.7441 - val_mae: 0.4409\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0560 - mae: 0.0407 - val_loss: 1.1169 - val_mae: 0.3948\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0412 - mae: 0.0305 - val_loss: 1.3955 - val_mae: 0.4332\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0506 - mae: 0.0347 - val_loss: 1.3116 - val_mae: 0.4048\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: 0.0361 - mae: 0.0289 - val_loss: 1.4552 - val_mae: 0.4344\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0320 - mae: 0.0248 - val_loss: 1.5295 - val_mae: 0.4414\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0410 - mae: 0.0296 - val_loss: 1.9017 - val_mae: 0.5077\n",
      "Epoch 42/100\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 0.0403 - mae: 0.0296\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0400 - mae: 0.0294 - val_loss: 1.5511 - val_mae: 0.4490\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: 0.0292 - mae: 0.0227 - val_loss: 1.6291 - val_mae: 0.4447\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: 0.0201 - mae: 0.0155 - val_loss: 1.7281 - val_mae: 0.4724\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: 0.0314 - mae: 0.0228 - val_loss: 1.4780 - val_mae: 0.4193\n",
      "Epoch 46/100\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 0.0227 - mae: 0.0164\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0231 - mae: 0.0168 - val_loss: 2.2759 - val_mae: 0.5146\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0240 - mae: 0.0179 - val_loss: 1.9030 - val_mae: 0.5115\n",
      "Epoch 48/100\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 0.0219 - mae: 0.0169\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 72s 4s/step - loss: 0.0216 - mae: 0.0167 - val_loss: 1.8327 - val_mae: 0.4740\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0181 - mae: 0.0137 - val_loss: 1.5446 - val_mae: 0.4474\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0173 - mae: 0.0133 - val_loss: 1.9607 - val_mae: 0.4982\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 74s 4s/step - loss: 0.0184 - mae: 0.0131 - val_loss: 1.6519 - val_mae: 0.4675\n",
      "Epoch 52/100\n",
      "14/20 [====================>.........] - ETA: 15s - loss: 0.0190 - mae: 0.0137"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-806b52387b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          early_stop, reduce_lr],\n\u001b[1;32m      7\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                validation_steps=5)\n\u001b[0m",
      "\u001b[0;32m~/pybr/projeto/venv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/pybr/projeto/venv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pybr/projeto/venv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pybr/projeto/venv/lib/python3.5/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "similarity_model.fit_generator(train_generator,\n",
    "                               steps_per_epoch=20,\n",
    "                               epochs=100,\n",
    "                               verbose=1,\n",
    "                               callbacks=[tensorboard_logs, mcp_save,\n",
    "                                         early_stop, reduce_lr],\n",
    "                               validation_data=validation_generator,\n",
    "                               validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files1 = [filename for filename in os.listdir(caminho_normal_train)\n",
    "                   if filename[-4:] in  ['.jpg', 'jpeg', '.png']]\n",
    "list_files2 = [filename for filename in os.listdir(caminho_pneumonia_train)\n",
    "                   if filename[-4:] in  ['.jpg', 'jpeg', '.png']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_files1))\n",
    "print(list_files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_files2))\n",
    "print(list_files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gym2",
   "language": "python",
   "name": "venv_gym2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
