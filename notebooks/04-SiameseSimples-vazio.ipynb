{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR = '../models/siamese'\n",
    "LOG_DIR = '../logs/04/'\n",
    "SIZE = (224, 224)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "caminho_bases = os.path.join('..', 'bases', 'vazios')\n",
    "caminho_train = os.path.join(caminho_bases, 'train')\n",
    "caminho_test = os.path.join(caminho_bases, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, \\\n",
    "    ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "tensorboard_logs = TensorBoard(log_dir=LOG_DIR, histogram_freq=1,\n",
    "                               write_graph=False, write_images=False,\n",
    "                               update_freq='epoch')\n",
    "mcp_save = ModelCheckpoint(os.path.join(MODEL_DIR, \n",
    "                                        '04modelweights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                           save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=2,\n",
    "                              verbose=1, min_delta=1e-2, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "=================================================================\n",
      "Total params: 1,064,608\n",
      "Trainable params: 1,064,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Conv2D, \\\n",
    "    BatchNormalization, concatenate, Dense, Dropout, Flatten, Input, MaxPooling2D\n",
    "\n",
    "\n",
    "SIZE = (224, 224)\n",
    "\n",
    "\n",
    "nuclear_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                         padding='same',\n",
    "                         activation='relu',\n",
    "                         input_shape=(*SIZE, 3)),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(256, (3, 3), activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    " \n",
    "])\n",
    "\n",
    "nuclear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Similarity_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          1064608     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features (Concatenate)    (None, 256)          0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           4112        merge_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            68          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4)            16          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            5           activation_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,068,873\n",
      "Trainable params: 1,068,833\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a_in = Input(shape=(*SIZE, 3))\n",
    "b_in = Input(shape=(*SIZE, 3))\n",
    "\n",
    "a_feat = nuclear_model(a_in)\n",
    "b_feat = nuclear_model(b_in)\n",
    "\n",
    "combined_features = concatenate([a_feat, b_feat], name = 'merge_features')\n",
    "combined_features = Dense(16, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(4, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = tf.keras.Model(inputs = [a_in, b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()\n",
    "\n",
    "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_nvazio_train = os.path.join(caminho_train, 'nvazio')\n",
    "caminho_vazio_train = os.path.join(caminho_train, 'vazio')\n",
    "caminho_nvazio_test = os.path.join(caminho_test, 'nvazio')\n",
    "caminho_vazio_test = os.path.join(caminho_test, 'vazio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def generate_random_batch(nvazios_list, vazios_list, batch_size=32):\n",
    "    def get_item(classe):\n",
    "        if classe == 0:\n",
    "            return nvazios_list.pop()\n",
    "        return vazios_list.pop()\n",
    "    result = []\n",
    "    for i in range(batch_size):\n",
    "        classe1 = random.randint(0, 1)\n",
    "        item1 = get_item(classe1) \n",
    "        classe2 = random.randint(0, 1)\n",
    "        item2 = get_item(classe2)\n",
    "        if classe1 == classe2:\n",
    "            if item1 == item2:\n",
    "                alpha = 0\n",
    "            else:\n",
    "                alpha = 0.001\n",
    "        else:\n",
    "            alpha = 1\n",
    "        result.append((item1, item2, alpha))\n",
    "    return result  \n",
    "\n",
    "def image_generator(caminho1, caminho2, batch_size=32):\n",
    "    list_files1 = os.listdir(caminho1)\n",
    "    list_files2 = os.listdir(caminho2)\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    while True:\n",
    "        # Ciclar lista (se acabar, recarregar do come√ßo)\n",
    "        if len(list1) < batch_size * 2:\n",
    "            random.shuffle(list_files1)\n",
    "            list1 = [os.path.join(caminho1, arq) for arq in list_files1]\n",
    "        if len(list2) < batch_size * 2:\n",
    "            random.shuffle(list_files2)\n",
    "            list2 = [os.path.join(caminho2, arq) for arq in list_files2]\n",
    "        # Gerar um batch da lista\n",
    "        triples = generate_random_batch(list1, list2)\n",
    "        X1 = np.zeros((batch_size, *SIZE, 3))\n",
    "        X2 = np.zeros((batch_size, *SIZE, 3))\n",
    "        y = np.zeros((batch_size, 1))\n",
    "        '''for ind, triple in enumerate(triples):\n",
    "            pil_img1 = Image.open(triple[0])\n",
    "            pil_img1 = pil_img1.resize(SIZE, Image.ANTIALIAS)\n",
    "            pil_img2 = Image.open(triple[1])\n",
    "            pil_img2 = pil_img2.resize(SIZE, Image.ANTIALIAS)\n",
    "            label = triple[2]\n",
    "            X1[ind, :, :, :] = np.array(pil_img1) / 255.\n",
    "            X2[ind, :, :, :] = np.array(pil_img2) / 255.\n",
    "            y[ind, :] = label\n",
    "        '''\n",
    "        yield [X1, X2], y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = image_generator(caminho_nvazio_train, caminho_vazio_train)\n",
    "validation_generator = image_generator(caminho_nvazio_test, caminho_vazio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.4244 - mae: 0.3112 - val_loss: 0.1121 - val_mae: 0.1060\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.2356 - mae: 0.2025 - val_loss: 0.1991 - val_mae: 0.1805\n",
      "Epoch 3/100\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1890 - mae: 0.1643\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.1890 - mae: 0.1642 - val_loss: 0.2678 - val_mae: 0.2349\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1697 - mae: 0.1480 - val_loss: 0.4010 - val_mae: 0.3304\n",
      "Epoch 5/100\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1612 - mae: 0.1411\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1611 - mae: 0.1410 - val_loss: 0.3973 - val_mae: 0.3279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b39ade7f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_model.fit_generator(train_generator,\n",
    "                               steps_per_epoch=200,\n",
    "                               epochs=100,\n",
    "                               verbose=1,\n",
    "                               callbacks=[tensorboard_logs, mcp_save,\n",
    "                                         early_stop, reduce_lr],\n",
    "                               validation_data=validation_generator,\n",
    "                               validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gym2",
   "language": "python",
   "name": "venv_gym2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
