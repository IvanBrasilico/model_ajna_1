{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação entre modelos para definir publicação ou não em produção\n",
    "## Comparar:\n",
    "* Accuracy geral\n",
    "* Recall em vazios\n",
    "* Recall em não vazios\n",
    "* Velocidade\n",
    "* Uso de memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "SIZE = (224, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_basest = os.path.join('..', 'bases', 'vazios')\n",
    "caminho_traint = os.path.join(caminho_basest, 'train')\n",
    "caminho_testt = os.path.join(caminho_basest, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2317 images belonging to 2 classes.\n",
      "Found 20845 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    caminho_testt,\n",
    "    target_size=SIZE,\n",
    "    batch_size=128,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    caminho_traint,\n",
    "    target_size=SIZE,\n",
    "    batch_size=128,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar modelo scvvazios.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "SIZE = 128, 128\n",
    "MODEL_FILE = 'vaziossvc.pkl'\n",
    "\n",
    "\n",
    "class VazioSVMModel():\n",
    "    def __init__(self, size=SIZE):\n",
    "        self.size = size\n",
    "        self.model = joblib.load(MODEL_FILE)\n",
    "        self.input_shape = [SIZE[0] * SIZE[1]]\n",
    "\n",
    "    def image_prepare(self, image: Image):\n",
    "        image = image.resize(self.size, Image.ANTIALIAS)\n",
    "        image_array = np.asarray(image).astype('float32')\n",
    "        # del image\n",
    "        image_array = image_array[:, :, 0] / 255\n",
    "        # print(image_array.shape)\n",
    "        image_array = np.reshape(image_array,\n",
    "                                 image_array.shape[0] * image_array.shape[1])\n",
    "        return image_array\n",
    "\n",
    "    def prepara(self, image):\n",
    "        return self.image_prepare(image)\n",
    "\n",
    "    def predict(self, image: Image):\n",
    "        # O modelo SVM foi treinado em classificação binária\n",
    "        # 0 para vazio e 1 para não vazio\n",
    "        y = self.model.predict([self.image_prepare(image)]).tolist()\n",
    "        return 1 if y[0] == 0. else 0\n",
    "        # vazio = [{'vazio': y_ == 0} for y_ in y]\n",
    "        # return vazio\n",
    "    \n",
    "\n",
    "model1 = VazioSVMModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for filename in validation_generator.filenames:\n",
    "    pil_image = Image.open(os.path.join(caminho_testt, filename))\n",
    "    y_pred.append(model1.predict(pil_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555459646094088"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == validation_generator.labels) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95      1166\n",
      "          1       0.92      1.00      0.96      1151\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1063  103]\n",
      " [   0 1151]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar melhor modelo do notebook 01b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                         padding='same',\n",
    "                         activation='relu',\n",
    "                         input_shape=(*SIZE, 3)),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(256, (3, 3), activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.4),\n",
    "  Dense(1, activation='sigmoid')\n",
    " \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(os.path.join('..', 'models', 'B3modelweights.17-0.08.hdf5'))\n",
    "y_pred2 = model2.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620198532585239"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2_labels = y_pred2.reshape(-1) > 0.5\n",
    "\n",
    "sum(y_pred2_labels == validation_generator.labels) / len(y_pred2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      1166\n",
      "           1       0.93      1.00      0.96      1151\n",
      "\n",
      "    accuracy                           0.96      2317\n",
      "   macro avg       0.96      0.96      0.96      2317\n",
      "weighted avg       0.96      0.96      0.96      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels, y_pred2_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1078   88]\n",
      " [   0 1151]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels, y_pred2_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar melhor modelo do notebook 02c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317 2304 128 18\n",
      "last batch setted elements 2176:2304\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet',\n",
    "                         input_shape=(*SIZE, 3), \n",
    "                         include_top=False,\n",
    "                         pooling='max')\n",
    "\n",
    "def extract_features(generator, model):\n",
    "    generator.reset()\n",
    "    n_images = len(generator.filenames)\n",
    "    batch_size = generator.batch_size\n",
    "    m = batch_size *  (n_images // batch_size)  # Arredondar para não ficar espaço vazio\n",
    "    n = model.output.shape[1]\n",
    "    features = np.zeros((m, n), np.float32)\n",
    "    y_ = np.zeros((m, 1), np.float32)\n",
    "    print(n_images, m, batch_size, m // batch_size)\n",
    "    for ind in range(m // batch_size):\n",
    "        batch, y_batch = next(generator)\n",
    "        features_batch = base_model.predict(batch)\n",
    "        features[ind * batch_size: (ind * batch_size) + batch_size, :] = features_batch\n",
    "        y_[ind * batch_size: (ind * batch_size) + batch_size, 0] = y_batch\n",
    "    print('last batch setted elements %s:%s' % ((ind * batch_size), ((ind * batch_size) + batch_size)))\n",
    "    return features, y_\n",
    "\n",
    "features_test, y_test = extract_features(validation_generator, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=128,\n",
    "                       activation='relu',\n",
    "                       input_shape=(1024,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units=128,\n",
    "                       activation='relu',\n",
    "                       input_shape=(1024,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../models_featureextraction'\n",
    "\n",
    "epoch = 13\n",
    "val_loss = 0.10\n",
    "model.load_weights(\n",
    "    os.path.join(MODEL_DIR,\n",
    "                 'Transfermodelweights02c3-classweights.{:02d}-{:.2f}.hdf5'.format(epoch, val_loss)\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9526909722222222"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3_labels = y_pred3.reshape(-1) > 0.5\n",
    "\n",
    "sum(y_pred3_labels == validation_generator.labels[:len(y_pred3)]) / len(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1166\n",
      "           1       0.94      0.97      0.95      1138\n",
      "\n",
      "    accuracy                           0.95      2304\n",
      "   macro avg       0.95      0.95      0.95      2304\n",
      "weighted avg       0.95      0.95      0.95      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels[:len(y_pred3)], y_pred3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1096   70]\n",
      " [  39 1099]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels[:len(y_pred3)], y_pred3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gym2",
   "language": "python",
   "name": "venv_gym2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
