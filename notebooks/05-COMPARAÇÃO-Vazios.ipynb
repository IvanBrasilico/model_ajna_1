{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação entre modelos para definir publicação ou não em produção\n",
    "## Comparar:\n",
    "* Accuracy geral\n",
    "* Recall em vazios\n",
    "* Recall em não vazios\n",
    "* Velocidade\n",
    "* Uso de memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar imagens (para modelos 2 e 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_basest = os.path.join('..', 'bases', 'vazios')\n",
    "caminho_traint = os.path.join(caminho_basest, 'train')\n",
    "caminho_testt = os.path.join(caminho_basest, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2317 images belonging to 2 classes.\n",
      "Found 20845 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "SIZE = (224, 224)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    caminho_testt,\n",
    "    target_size=SIZE,\n",
    "    batch_size=128,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    caminho_traint,\n",
    "    target_size=SIZE,\n",
    "    batch_size=128,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar modelo scvvazios.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2317 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "SIZE = (128, 128)\n",
    "MODEL_FILE = 'vaziossvc.pkl'\n",
    "\n",
    "validation_generator_svc = validation_datagen.flow_from_directory(\n",
    "    caminho_testt,\n",
    "    target_size=SIZE,\n",
    "    batch_size=128,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "model1 = joblib.load(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "0 (128, 128, 128, 3)\n",
      "CPU times: user 5.13 s, sys: 0 ns, total: 5.13 s\n",
      "Wall time: 5.13 s\n",
      "1 (128, 128, 128, 3)\n",
      "CPU times: user 5.02 s, sys: 0 ns, total: 5.02 s\n",
      "Wall time: 5.01 s\n",
      "2 (128, 128, 128, 3)\n",
      "CPU times: user 5.12 s, sys: 3.66 ms, total: 5.12 s\n",
      "Wall time: 5.12 s\n",
      "3 (128, 128, 128, 3)\n",
      "CPU times: user 5.24 s, sys: 0 ns, total: 5.24 s\n",
      "Wall time: 5.24 s\n",
      "4 (128, 128, 128, 3)\n",
      "CPU times: user 5.12 s, sys: 0 ns, total: 5.12 s\n",
      "Wall time: 5.12 s\n",
      "5 (128, 128, 128, 3)\n",
      "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
      "Wall time: 5.11 s\n",
      "6 (128, 128, 128, 3)\n",
      "CPU times: user 5.2 s, sys: 0 ns, total: 5.2 s\n",
      "Wall time: 5.2 s\n",
      "7 (128, 128, 128, 3)\n",
      "CPU times: user 5.12 s, sys: 0 ns, total: 5.12 s\n",
      "Wall time: 5.12 s\n",
      "8 (128, 128, 128, 3)\n",
      "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
      "Wall time: 5.11 s\n",
      "9 (128, 128, 128, 3)\n",
      "CPU times: user 5.06 s, sys: 0 ns, total: 5.06 s\n",
      "Wall time: 5.06 s\n",
      "10 (128, 128, 128, 3)\n",
      "CPU times: user 5.1 s, sys: 0 ns, total: 5.1 s\n",
      "Wall time: 5.1 s\n",
      "11 (128, 128, 128, 3)\n",
      "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
      "Wall time: 5.11 s\n",
      "12 (128, 128, 128, 3)\n",
      "CPU times: user 5.29 s, sys: 2.57 ms, total: 5.29 s\n",
      "Wall time: 5.29 s\n",
      "13 (128, 128, 128, 3)\n",
      "CPU times: user 5.18 s, sys: 3.89 ms, total: 5.19 s\n",
      "Wall time: 5.19 s\n",
      "14 (128, 128, 128, 3)\n",
      "CPU times: user 5.05 s, sys: 7.94 ms, total: 5.06 s\n",
      "Wall time: 5.06 s\n",
      "15 (128, 128, 128, 3)\n",
      "CPU times: user 5.04 s, sys: 3.92 ms, total: 5.04 s\n",
      "Wall time: 5.04 s\n",
      "16 (128, 128, 128, 3)\n",
      "CPU times: user 5.04 s, sys: 0 ns, total: 5.04 s\n",
      "Wall time: 5.04 s\n",
      "17 (128, 128, 128, 3)\n",
      "CPU times: user 5.02 s, sys: 11.9 ms, total: 5.04 s\n",
      "Wall time: 5.03 s\n",
      "18 (13, 128, 128, 3)\n",
      "CPU times: user 510 ms, sys: 16 µs, total: 510 ms\n",
      "Wall time: 509 ms\n",
      "CPU times: user 1min 36s, sys: 90.6 ms, total: 1min 36s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred1 = []\n",
    "print(len(validation_generator_svc))\n",
    "for ind in range(len(validation_generator_svc)):\n",
    "    images, labels = next(validation_generator_svc)\n",
    "    print(ind, images.shape)\n",
    "    batch = images[:, :, :, 0]\n",
    "    image_array = np.reshape(batch, (images.shape[0], images.shape[1] * images.shape[2]))\n",
    "    %time predictions = model1.predict(image_array)\n",
    "    y_pred1.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = [0 if item == 1.0 else 1 for item in y_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555459646094088"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred1 == validation_generator.labels) / len(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.9117    0.9538      1166\n",
      "          1     0.9179    1.0000    0.9572      1151\n",
      "\n",
      "avg / total     0.9592    0.9555    0.9555      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels, y_pred1, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1063  103]\n",
      " [   0 1151]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar melhor modelo do notebook 01b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "SIZE = (224, 224)\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                         padding='same',\n",
    "                         activation='relu',\n",
    "                         input_shape=(*SIZE, 3)),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(128, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "  Conv2D(256, (3, 3), activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.4),\n",
    "  Dense(1, activation='sigmoid')\n",
    " \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(os.path.join('..', 'models', 'B3modelweights.17-0.08.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 s, sys: 1.21 s, total: 7.85 s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%time y_pred2 = model2.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620198532585239"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2_labels = y_pred2.reshape(-1) > 0.5\n",
    "\n",
    "sum(y_pred2_labels == validation_generator.labels) / len(y_pred2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.9245    0.9608      1166\n",
      "          1     0.9290    1.0000    0.9632      1151\n",
      "\n",
      "avg / total     0.9647    0.9620    0.9620      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels, y_pred2_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1078   88]\n",
      " [   0 1151]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels, y_pred2_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar melhor modelo do notebook 02c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "SIZE = (224, 224)\n",
    "base_model = DenseNet121(weights='imagenet',\n",
    "                         input_shape=(*SIZE, 3), \n",
    "                         include_top=False,\n",
    "                         pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317 128 18\n",
      "last batch setted elements 2304:2317\n",
      "CPU times: user 21.7 s, sys: 3.59 s, total: 25.3 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "def extract_features(generator, model):\n",
    "    generator.reset()\n",
    "    n_images = len(generator.filenames)\n",
    "    batch_size = generator.batch_size\n",
    "    m = batch_size *  (n_images // batch_size)  # Arredondar para não ficar espaço vazio\n",
    "    m = n_images\n",
    "    n = model.output.shape[1]\n",
    "    features = np.zeros((m, n), np.float32)\n",
    "    y_ = np.zeros((m, 1), np.float32)\n",
    "    print(m, batch_size, m // batch_size)\n",
    "    for ind in range(0, m + 1, batch_size):\n",
    "        batch, y_batch = next(generator)\n",
    "        features_batch = base_model.predict(batch)\n",
    "        posi = ind * batch_size\n",
    "        features[ind: ind + len(y_batch), :] = features_batch\n",
    "        y_[ind: ind + len(y_batch), 0] = y_batch\n",
    "    print('last batch setted elements %s:%s' % (ind, ind + len(y_batch)))\n",
    "    return features, y_\n",
    "\n",
    "%time features_test, y_test = extract_features(validation_generator, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=128,\n",
    "                       activation='relu',\n",
    "                       input_shape=(1024,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units=128,\n",
    "                       activation='relu',\n",
    "                       input_shape=(1024,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../models_featureextraction'\n",
    "\n",
    "epoch = 40\n",
    "val_loss = 0.08\n",
    "model.load_weights(\n",
    "    os.path.join(MODEL_DIR,\n",
    "                 'Transfermodelweights02c3.{:02d}-{:.2f}.hdf5'.format(epoch, val_loss)\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.8 ms, sys: 4.47 ms, total: 74.3 ms\n",
      "Wall time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred3a = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598618903754855"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3a_labels = y_pred3a.reshape(-1) > 0.5\n",
    "\n",
    "sum(y_pred3a_labels == validation_generator.labels) / len(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9900    0.9297    0.9589      1166\n",
      "          1     0.9329    0.9904    0.9608      1151\n",
      "\n",
      "avg / total     0.9616    0.9599    0.9598      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels, y_pred3a_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1084   82]\n",
      " [  11 1140]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels, y_pred3a_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../models_featureextraction'\n",
    "\n",
    "epoch = 13\n",
    "val_loss = 0.10\n",
    "model.load_weights(\n",
    "    os.path.join(MODEL_DIR,\n",
    "                 'Transfermodelweights02c3-classweights.{:02d}-{:.2f}.hdf5'.format(epoch, val_loss)\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.9 ms, sys: 5.31 ms, total: 69.2 ms\n",
      "Wall time: 43 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred3 = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2317, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529564091497627"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3_labels = y_pred3.reshape(-1) > 0.5\n",
    "\n",
    "sum(y_pred3_labels == validation_generator.labels) / len(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9656    0.9400    0.9526      1166\n",
      "          1     0.9408    0.9661    0.9533      1151\n",
      "\n",
      "avg / total     0.9533    0.9530    0.9530      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.labels[:len(y_pred3)], y_pred3_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1096   70]\n",
      " [  39 1112]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(validation_generator.labels[:len(y_pred3)], y_pred3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9401197604790419"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1099 / (1099 + 70)  # Não Vazios classificados \"erradamente\" como vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661164205039097"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1112 / (1112 + 39)  # Vazios classificados \"erradamente\" como não vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos1 = y_pred1 == validation_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos2 = y_pred2_labels == validation_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos3 = y_pred3_labels == validation_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos3a = y_pred3a_labels == validation_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935261113508848"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acertos1 == acertos2) / len(acertos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9753992231333621"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acertos2 == acertos3) / len(acertos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689253344842469"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acertos1 == acertos3) / len(acertos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827362969356928"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acertos3 == acertos3a) / len(acertos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9909365558912386"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acertos2 == acertos3a) / len(acertos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gym2",
   "language": "python",
   "name": "venv_gym2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
