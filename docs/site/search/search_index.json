{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Treinamento de modelos de vis\u00e3o computacional Abstract Nestes documentos centralizadas as anota\u00e7\u00f5es e hist\u00f3rico detalhado do treinamento de alguns modelos de vis\u00e3o computacional. Proposta do projeto - Capstone Proposal Detalhes dos modelos desenvolvidos e explora\u00e7\u00e3o de dados C\u00f3digo Fonte Organiza\u00e7\u00e3o O trabalho foi dividido em v\u00e1rios notebooks para melhor organiza\u00e7\u00e3o. Estes notebooks est\u00e3o com a seguinte nomenclatura <n\u00famero sequencial t\u00e9cnica/modelo><refinamento>-<descricao>-<base> Ex: 01 - n\u00famero sequencial b - refinamento Transfer Learning - t\u00e9cnica vazios - base de dados Assim: 01-RedeSimples-chestXRay \u00e9 uma rede neural simples para classificar a base chestXRay 01-RedeSimples-vazios \u00e9 uma rede neural simples para classificar a base vazios 01b-RedeSimples-vazios \u00e9 a mesma rede/t\u00e9cnica do 01 mas com algumas modifica\u00e7\u00f5es Modelos/bases Conforme detalhado em CapstoneProject, ser\u00e3o treinadas redes convolucionais simples do zero, modelos sofisticados com transfer learning, e redes siameas. As bases utilizadas ser\u00e3o chestXRay, vazios e ncmsunicos.","title":"Home"},{"location":"#treinamento-de-modelos-de-visao-computacional","text":"","title":"Treinamento de modelos de vis\u00e3o computacional"},{"location":"#abstract","text":"Nestes documentos centralizadas as anota\u00e7\u00f5es e hist\u00f3rico detalhado do treinamento de alguns modelos de vis\u00e3o computacional. Proposta do projeto - Capstone Proposal Detalhes dos modelos desenvolvidos e explora\u00e7\u00e3o de dados C\u00f3digo Fonte","title":"Abstract"},{"location":"#organizacao","text":"O trabalho foi dividido em v\u00e1rios notebooks para melhor organiza\u00e7\u00e3o. Estes notebooks est\u00e3o com a seguinte nomenclatura <n\u00famero sequencial t\u00e9cnica/modelo><refinamento>-<descricao>-<base> Ex: 01 - n\u00famero sequencial b - refinamento Transfer Learning - t\u00e9cnica vazios - base de dados Assim: 01-RedeSimples-chestXRay \u00e9 uma rede neural simples para classificar a base chestXRay 01-RedeSimples-vazios \u00e9 uma rede neural simples para classificar a base vazios 01b-RedeSimples-vazios \u00e9 a mesma rede/t\u00e9cnica do 01 mas com algumas modifica\u00e7\u00f5es","title":"Organiza\u00e7\u00e3o"},{"location":"#modelosbases","text":"Conforme detalhado em CapstoneProject, ser\u00e3o treinadas redes convolucionais simples do zero, modelos sofisticados com transfer learning, e redes siameas. As bases utilizadas ser\u00e3o chestXRay, vazios e ncmsunicos.","title":"Modelos/bases"},{"location":"notebooks/","text":"ChestXRay notebooks na base chestXRay 01-Baseline-redesimples-chestXRay 01-Baseline-redesimples-chestXRay Rede convolucional bem simples treinada do zero. Input shape = 150, 150 acc: 0.9279 - val_acc: 0.8285 01b-Baseline-redesimples-chestXRay-tamanhomaior 01b-Baseline-redesimples-chestXRay-tamanhomaior Rede convolucional bem simples treinada do zero. Treinamento em 04/09/2019: Foram realizadas v\u00e1rias rodadas(sempre continuando pesos do menor val_loss anterior): A primeira com ImageAugmentation e lr=0.001, melhor acc=0.94 e melhor val_acc=0.82 Mesmo a rede sendo simples, aparenta ligeiro overfitting A segunda com lr=0.0001 e mais \u00e9pocas para os callbacks, melhor acc=0.94 e melhor val_acc=0.83 A terceira sem ImageAugmentation, com lr muito pequena. Embora ImageAugmentation seja uma t\u00e9cnica para reduzir overfitting, e a priori tirar possa parecer contrasenso, apenas para testar se deixar a base de treinamento mais parecida com a de testes reduz erro de generaliza\u00e7\u00e3o, ao menos nesses exemplos e no \"fine tunning\" Conforme previsto pela teoria, o sobreajuste aumentou. acc foi para 0.96 e val_acc caiu para menos de 0.80 Quarta tentativa, com regulariza\u00e7\u00e3o L1 e L2 na \u00faltima camada e otimizador Adam, pareceu que ia conseguir melhoria, foi expandido o treinamento para 50 \u00e9pocas iniciando com uma lr maior, mas a melhoria foi apenas marginal, com val_acc ensaiando ultrapassar 0.87 mas oscilando bastante Em 04/06/2019 o melhor modelo foi: Epoch 14/50 acc: 0.9507 val_acc: 0.8429 Conclus\u00f5es/pr\u00f3ximos passos Tentar aumentar regulariza\u00e7\u00e3o, utilizar keras-tuner Testar modelo pr\u00e9-treinado mais poderoso (TransferLearning) Olhar exemplos de kernel no kaggle com melhor desempenho em busca de id\u00e9ias 02c-TransferLearningSimples-FeatureExtractionRegularizer-chestXRay 02c-TransferLearningSimplesFeatureExtractionRegularizer-chestXRay Utilizar DenseNet121 como feature extraction. Treinar classificador na sa\u00edda desta rede. Resultado testes: acc: 0.93 val_acc: 0.82 Pr\u00f3ximo passo: Gravar em .npy uma matriz com todas as features extra\u00eddas da base de treinamento e fazer Grid Search e Random Search do melhor classificador obtido. 02d-TransferLearning-FeatureExtraction-HyperParamTuner-chestXRay 02d-TransferLearningFeatureExtractionHyperParamTuner-chestXRay Esta rede usa como entrada uma \u00faltima camada maxpooling j\u00e1 salva, de sa\u00edda da DenseNet121 aplicada \u00e0 base de treinamento. Como todo o processamento convolucional j\u00e1 est\u00e1 realizado, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, facilita o tunning da camada classificadora. Resultado: Foi poss\u00edvel obter um classificador utilizando somente a sa\u00edda da DenseNet121 original com pesos da imagenet: Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.95 0.97 02e-auxiliar-ImageAugmentation 02e-auxiliar-ImageAugmentation Este notebook \u00e9 apenas para gerar uma base aumentada pr\u00e9-processada. Ser\u00e1 utilizado pelo outro notebook 02e. O objetivo \u00e9 tentar diminuir o sobreajuste / dist\u00e3ncia entre acc e val_acc e agilizar a fase de treinamento. 02e-FineTunning-chestXRay 02e-FineTunning-chestXRay Aqui est\u00e1 sendo treinada uma rede DenseNet121 do 02c empilhada com o classificador do 02d. Problemas: n\u00e3o ficou claro se os pesos do notebook 02d foram aproveitados. Eles s\u00e3o carregados, os testes d\u00e3o resultado similar ao 02d, mas quando inicia o treinamento de fine tunning os n\u00fameros de acc e val_acc caem pr\u00f3ximos de 0.5, para depois voltarem a subir, mesmo quando se utiliza uma lr extremamente baixa. Melhor modelo: Transfermodelweights02e_etapa2.02-0.66.hdf5 Base aumentada: acc 0.99 val_acc 0.83 Obs: Houve um problema, o acc na base train indica 99% no treinamento, mas estranhamente cai para 95% no relat\u00f3rio. Investigar. Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 Observa\u00e7\u00f5es finais Considero que para este tipo de problema, o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 Vazios notebooks container vazio-nvazio 01-Baseline-redesimples-vazio 01-Baseline-redesimples-vazio Rede convolucional bem simples treinada do zero. acc: 0.9551 - val_acc: 0.9564 Este notebook tamb\u00e9m cont\u00e9m visualiza\u00e7\u00f5es para tentar entender melhor o que foi aprendido pela rede. 01b-Baseline-redesimples-vazio-tamanhomaior 01b-Baseline-redesimples-vazio-tamanhomaior Mesma rede convolucional, mas treinada com entrada maior (224x224). O tamanho de entrada \u00e9 o mesmo da maioria dos modelos treinados na imagenet. acc: 0.9589 - val_acc: 0.9616 Em 26/06/2019: Rodada tr\u00eas vezes a sequ\u00eancia acima, 99, 101 e 103 erros de classifica\u00e7\u00e3o (a mudan\u00e7a \u00e9 devido a t\u00e9cnicas de image augmentation). Precis\u00e3o de 100% na classe 0 e recall 91% ou seja 9% de erros tipo II falso negativo (predi\u00e7\u00e3o 1 r\u00f3tulo 0). Analisando visualmente o diret\u00f3rio, pelo menos 25% dos erros s\u00e3o de rotulagem (os cont\u00eaineres realmente n\u00e3o cont\u00e9m carga. Dos 70-75 erros restantes, em 20% do total o cont\u00eainer est\u00e1 escuro, parecendo ter carga de espuma. Em torno de 30% do total tamb\u00e9m h\u00e1 diversos tipos de ru\u00eddos na imagem, desde carretas que invadem a \u00e1rea do cont\u00eainer at\u00e9 borr\u00f5es laterais na imagem, mas n\u00e3o carga. Ent\u00e3o tamb\u00e9m \u00e9 cont\u00eainer efetivamente vazio. Nos erros restantes (apenas 20% de 9%) parece haver erro de classifica\u00e7\u00e3o, mas o cont\u00eainer cont\u00e9m pouca carga. Conclus\u00f5es: * O erro real do algoritmo pode ser de apenas 2-4% e apenas na classe N\u00e3o Vazio. Este erro poderia ser melhorado com melhora no recorte do cont\u00eainer e na limpeza da imagem original. * Dos 9% de erros, 2% s\u00e3o aparentemente \"fraudes\": cont\u00eaineres n\u00e3o continham carga * Dos 9% de erros, 2% podem ser \"fraude\" ou falha no esc\u00e2ner * Necess\u00e1rio proibir carretas que obstruam o cont\u00eainer O algoritmo est\u00e1 tentendo a ignorar cargas de cont\u00eaineres declarados como vazios mas borrados/sujos ou com muito pouca carga ou com carga uniforme de espumas/materias pouco densos. Talvez fosse interessante for\u00e7ar o algoritmo a ser mais tendente a diminuir este erro, mesmo que isto custasse aumento de falso positivo na classe vazio. 01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered 01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Base aumentada: acc: 0.97 - val_acc: 0.97 Base original: acc: 0.96 - val_acc: 0.96 01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform 01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostransform Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Al\u00e9m disso, na inspe\u00e7\u00e3o visual do notebook 01b2 ficou a impress\u00e3o de que os erros que ainda estavam ocorrendo eram: erros que mesmo o humano teria dificuldade (cont\u00eaineres com espuma, por exemplo) ou erros de r\u00f3tulo persistentes. Al\u00e9m desses, o algoritmo ainda erra em alguns poucos casos de cont\u00eainer contendo muito pouca carga, especialmente se esta se concentra apenas no solo (provavelmente confunde com imagens de vazio com solo polu\u00eddo por carretas) ou somente em uma das portas (provavelmente confundindo com reefer). Assim, neste notebook foi diminu\u00edda a amplitude das transforma\u00e7\u00f5es de imagem aumentada para checar o resultado. Base aumentada: acc: 0.97 - val_acc: 0.98 Base original: acc: 0.96 - val_acc: 0.96 02-TransferLearningSimples-vazio 02-TransferLearningSimples-vazio Rede Densenet121, pr\u00e9 treinada na imagenet. acc: 0.9545 - val_acc: 0.7126 Claramente, houve um sobreajuste muito grande. Os erros de classifica\u00e7\u00e3o cometidos s\u00e3o gritantes. Foi realizado fine tunning do \u00faltimo bloco convolucional (conv5): acc: 0.9523 - val_acc: 0.8045 Apesar dos resultados ruins na generaliza\u00e7\u00e3o, necess\u00e1rio explorar mais esta possibilidade. A dificuldade pode ser devido ao bias em textura da imagenet. Note-se que esta base \u00e9 em tons de cinza, e o mais importante \u00e9 a geometria. Imagenet \u00e9 colorida e textura \u00e9 importante. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness https://arxiv.org/abs/1811.12231 02b-TransferLearningSimplesRegularizer-vazio 02b-TransferLearningSimplesRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. N\u00e3o houve sucesso neste treinamento, necess\u00e1rio debugar posteriormente 02c-TransferLearning-FeatureExtractionRegularizer-vazio 02c-TransferLearningSimplesFeatureExtractionRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. acc: 0.9408 - val_acc: 0.9514 Neste caso, se optou por utilizar as camadas pr\u00e9 treinadas para feature extraction, e, foi utilizada Max Pooling na \u00faltima camada em vez de Avg Pooling. Observa\u00e7\u00f5es: Ap\u00f3s a extra\u00e7\u00e3o das features das imagens, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, a extra\u00e7\u00e3o separada dos features permitir\u00e1 treinar v\u00e1rios classificadores, fazer grid search e cross validation, entre outros. Conforme demonstrado acima, h\u00e1 entre as imagens da classe nvazio diversos exemplos que parecem da classe vazio. Ou s\u00e3o erros de base ou s\u00e3o exemplos extremamente similares aos vazios. O aprendizado deve melhorar eliminando estes da base. Ser\u00e1 criada uma c\u00f3pia da base sem esses exemplos, para testar os mesmos algoritmos e comparar. 02c2-TransferLearningFeatureExtraction-Vazio 02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" (teste 01b3) produzida por 02c e o2d2 Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Base original maxpool: acc: 0.9604 - val_acc: 0.9566 Base original avgpool: acc: 0.9594 - val_acc: 0.9588 Parece que n\u00e3o importa o que se tente, h\u00e1 um plat\u00f4 em torno de 0.96 para accuracy na base original. Com a base \"limpa\" de alguns erros de rotulagem, foi poss\u00edvel subir este plat\u00f4 para um pouco mais de 97%. Como a maioria dos erros \u00e9 na classe vazio, antes de prosseguir: * Testar neste mesmo notebook treinamento com class_weigth * Copiar este notebook e repetir mesmos passos na base gerada por 02d2 O uso de class_weight 3 para a classe 0 (n\u00e3o vazio) causou queda marginal na accuracy total, mas distribuindo melhor os erros, conforme tabela abaixo ( a accuracy caiu nas casas centesimais, em torno de 4 cent\u00e9simos): BASE TEST Sem class_weight precision recall f1-score support 0.0 0.99 0.92 0.96 1166 1.0 0.93 0.99 0.96 1138 Com class_weight precision recall f1-score support 0.0 0.97 0.94 0.95 1166 1.0 0.94 0.97 0.95 1138 BASE TRAIN Sem class_weight precision recall f1-score support 0.0 1.00 0.93 0.96 10494 1.0 0.93 1.00 0.96 10306 Com class_weight precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306 02c3-TransferLearningFeatureExtraction-Vazio 02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" e filtrado (mesma base que notebook 01b3) Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Detalhes no notebook. Resumindo, os resultados foram muito similares ao notebook 01b3: aumento de 2% em accuracy em rela\u00e7\u00e3o \u00e0 base original, provavelmente pela corre\u00e7\u00e3o de erros de r\u00f3tulo De resto, resultados similares ao notebook 02c2, em todas as tabelas (com o aumento de quase 2%) 02d-auxiliar-ImageAugmentation-Vazios 02d-auxiliar-ImageAugmentation-Vazios Notebook auxiliar para gerar uma base aumentada. 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es. 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es. Observa\u00e7\u00f5es Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpoll nos resultados e menor tempo de converg\u00eancia.","title":"Relat\u00f3rio"},{"location":"notebooks/#chestxray","text":"","title":"ChestXRay"},{"location":"notebooks/#notebooks-na-base-chestxray","text":"","title":"notebooks na base chestXRay"},{"location":"notebooks/#01-baseline-redesimples-chestxray","text":"01-Baseline-redesimples-chestXRay Rede convolucional bem simples treinada do zero. Input shape = 150, 150 acc: 0.9279 - val_acc: 0.8285","title":"01-Baseline-redesimples-chestXRay"},{"location":"notebooks/#01b-baseline-redesimples-chestxray-tamanhomaior","text":"01b-Baseline-redesimples-chestXRay-tamanhomaior Rede convolucional bem simples treinada do zero. Treinamento em 04/09/2019: Foram realizadas v\u00e1rias rodadas(sempre continuando pesos do menor val_loss anterior): A primeira com ImageAugmentation e lr=0.001, melhor acc=0.94 e melhor val_acc=0.82 Mesmo a rede sendo simples, aparenta ligeiro overfitting A segunda com lr=0.0001 e mais \u00e9pocas para os callbacks, melhor acc=0.94 e melhor val_acc=0.83 A terceira sem ImageAugmentation, com lr muito pequena. Embora ImageAugmentation seja uma t\u00e9cnica para reduzir overfitting, e a priori tirar possa parecer contrasenso, apenas para testar se deixar a base de treinamento mais parecida com a de testes reduz erro de generaliza\u00e7\u00e3o, ao menos nesses exemplos e no \"fine tunning\" Conforme previsto pela teoria, o sobreajuste aumentou. acc foi para 0.96 e val_acc caiu para menos de 0.80 Quarta tentativa, com regulariza\u00e7\u00e3o L1 e L2 na \u00faltima camada e otimizador Adam, pareceu que ia conseguir melhoria, foi expandido o treinamento para 50 \u00e9pocas iniciando com uma lr maior, mas a melhoria foi apenas marginal, com val_acc ensaiando ultrapassar 0.87 mas oscilando bastante Em 04/06/2019 o melhor modelo foi: Epoch 14/50 acc: 0.9507 val_acc: 0.8429 Conclus\u00f5es/pr\u00f3ximos passos Tentar aumentar regulariza\u00e7\u00e3o, utilizar keras-tuner Testar modelo pr\u00e9-treinado mais poderoso (TransferLearning) Olhar exemplos de kernel no kaggle com melhor desempenho em busca de id\u00e9ias","title":"01b-Baseline-redesimples-chestXRay-tamanhomaior"},{"location":"notebooks/#02c-transferlearningsimples-featureextractionregularizer-chestxray","text":"02c-TransferLearningSimplesFeatureExtractionRegularizer-chestXRay Utilizar DenseNet121 como feature extraction. Treinar classificador na sa\u00edda desta rede. Resultado testes: acc: 0.93 val_acc: 0.82 Pr\u00f3ximo passo: Gravar em .npy uma matriz com todas as features extra\u00eddas da base de treinamento e fazer Grid Search e Random Search do melhor classificador obtido.","title":"02c-TransferLearningSimples-FeatureExtractionRegularizer-chestXRay"},{"location":"notebooks/#02d-transferlearning-featureextraction-hyperparamtuner-chestxray","text":"02d-TransferLearningFeatureExtractionHyperParamTuner-chestXRay Esta rede usa como entrada uma \u00faltima camada maxpooling j\u00e1 salva, de sa\u00edda da DenseNet121 aplicada \u00e0 base de treinamento. Como todo o processamento convolucional j\u00e1 est\u00e1 realizado, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, facilita o tunning da camada classificadora. Resultado: Foi poss\u00edvel obter um classificador utilizando somente a sa\u00edda da DenseNet121 original com pesos da imagenet: Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.95 0.97","title":"02d-TransferLearning-FeatureExtraction-HyperParamTuner-chestXRay"},{"location":"notebooks/#02e-auxiliar-imageaugmentation","text":"02e-auxiliar-ImageAugmentation Este notebook \u00e9 apenas para gerar uma base aumentada pr\u00e9-processada. Ser\u00e1 utilizado pelo outro notebook 02e. O objetivo \u00e9 tentar diminuir o sobreajuste / dist\u00e3ncia entre acc e val_acc e agilizar a fase de treinamento.","title":"02e-auxiliar-ImageAugmentation"},{"location":"notebooks/#02e-finetunning-chestxray","text":"02e-FineTunning-chestXRay Aqui est\u00e1 sendo treinada uma rede DenseNet121 do 02c empilhada com o classificador do 02d. Problemas: n\u00e3o ficou claro se os pesos do notebook 02d foram aproveitados. Eles s\u00e3o carregados, os testes d\u00e3o resultado similar ao 02d, mas quando inicia o treinamento de fine tunning os n\u00fameros de acc e val_acc caem pr\u00f3ximos de 0.5, para depois voltarem a subir, mesmo quando se utiliza uma lr extremamente baixa. Melhor modelo: Transfermodelweights02e_etapa2.02-0.66.hdf5 Base aumentada: acc 0.99 val_acc 0.83 Obs: Houve um problema, o acc na base train indica 99% no treinamento, mas estranhamente cai para 95% no relat\u00f3rio. Investigar. Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97","title":"02e-FineTunning-chestXRay"},{"location":"notebooks/#observacoes-finais","text":"Considero que para este tipo de problema, o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97","title":"Observa\u00e7\u00f5es finais"},{"location":"notebooks/#vazios","text":"","title":"Vazios"},{"location":"notebooks/#notebooks-container-vazio-nvazio","text":"","title":"notebooks container vazio-nvazio"},{"location":"notebooks/#01-baseline-redesimples-vazio","text":"01-Baseline-redesimples-vazio Rede convolucional bem simples treinada do zero. acc: 0.9551 - val_acc: 0.9564 Este notebook tamb\u00e9m cont\u00e9m visualiza\u00e7\u00f5es para tentar entender melhor o que foi aprendido pela rede.","title":"01-Baseline-redesimples-vazio"},{"location":"notebooks/#01b-baseline-redesimples-vazio-tamanhomaior","text":"01b-Baseline-redesimples-vazio-tamanhomaior Mesma rede convolucional, mas treinada com entrada maior (224x224). O tamanho de entrada \u00e9 o mesmo da maioria dos modelos treinados na imagenet. acc: 0.9589 - val_acc: 0.9616 Em 26/06/2019: Rodada tr\u00eas vezes a sequ\u00eancia acima, 99, 101 e 103 erros de classifica\u00e7\u00e3o (a mudan\u00e7a \u00e9 devido a t\u00e9cnicas de image augmentation). Precis\u00e3o de 100% na classe 0 e recall 91% ou seja 9% de erros tipo II falso negativo (predi\u00e7\u00e3o 1 r\u00f3tulo 0). Analisando visualmente o diret\u00f3rio, pelo menos 25% dos erros s\u00e3o de rotulagem (os cont\u00eaineres realmente n\u00e3o cont\u00e9m carga. Dos 70-75 erros restantes, em 20% do total o cont\u00eainer est\u00e1 escuro, parecendo ter carga de espuma. Em torno de 30% do total tamb\u00e9m h\u00e1 diversos tipos de ru\u00eddos na imagem, desde carretas que invadem a \u00e1rea do cont\u00eainer at\u00e9 borr\u00f5es laterais na imagem, mas n\u00e3o carga. Ent\u00e3o tamb\u00e9m \u00e9 cont\u00eainer efetivamente vazio. Nos erros restantes (apenas 20% de 9%) parece haver erro de classifica\u00e7\u00e3o, mas o cont\u00eainer cont\u00e9m pouca carga. Conclus\u00f5es: * O erro real do algoritmo pode ser de apenas 2-4% e apenas na classe N\u00e3o Vazio. Este erro poderia ser melhorado com melhora no recorte do cont\u00eainer e na limpeza da imagem original. * Dos 9% de erros, 2% s\u00e3o aparentemente \"fraudes\": cont\u00eaineres n\u00e3o continham carga * Dos 9% de erros, 2% podem ser \"fraude\" ou falha no esc\u00e2ner * Necess\u00e1rio proibir carretas que obstruam o cont\u00eainer O algoritmo est\u00e1 tentendo a ignorar cargas de cont\u00eaineres declarados como vazios mas borrados/sujos ou com muito pouca carga ou com carga uniforme de espumas/materias pouco densos. Talvez fosse interessante for\u00e7ar o algoritmo a ser mais tendente a diminuir este erro, mesmo que isto custasse aumento de falso positivo na classe vazio.","title":"01b-Baseline-redesimples-vazio-tamanhomaior"},{"location":"notebooks/#01b2-baseline-redesimples-vazio-tamanhomaior-augmented-filtered","text":"01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Base aumentada: acc: 0.97 - val_acc: 0.97 Base original: acc: 0.96 - val_acc: 0.96","title":"01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered"},{"location":"notebooks/#01b3-baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform","text":"01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostransform Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Al\u00e9m disso, na inspe\u00e7\u00e3o visual do notebook 01b2 ficou a impress\u00e3o de que os erros que ainda estavam ocorrendo eram: erros que mesmo o humano teria dificuldade (cont\u00eaineres com espuma, por exemplo) ou erros de r\u00f3tulo persistentes. Al\u00e9m desses, o algoritmo ainda erra em alguns poucos casos de cont\u00eainer contendo muito pouca carga, especialmente se esta se concentra apenas no solo (provavelmente confunde com imagens de vazio com solo polu\u00eddo por carretas) ou somente em uma das portas (provavelmente confundindo com reefer). Assim, neste notebook foi diminu\u00edda a amplitude das transforma\u00e7\u00f5es de imagem aumentada para checar o resultado. Base aumentada: acc: 0.97 - val_acc: 0.98 Base original: acc: 0.96 - val_acc: 0.96","title":"01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform"},{"location":"notebooks/#02-transferlearningsimples-vazio","text":"02-TransferLearningSimples-vazio Rede Densenet121, pr\u00e9 treinada na imagenet. acc: 0.9545 - val_acc: 0.7126 Claramente, houve um sobreajuste muito grande. Os erros de classifica\u00e7\u00e3o cometidos s\u00e3o gritantes. Foi realizado fine tunning do \u00faltimo bloco convolucional (conv5): acc: 0.9523 - val_acc: 0.8045 Apesar dos resultados ruins na generaliza\u00e7\u00e3o, necess\u00e1rio explorar mais esta possibilidade. A dificuldade pode ser devido ao bias em textura da imagenet. Note-se que esta base \u00e9 em tons de cinza, e o mais importante \u00e9 a geometria. Imagenet \u00e9 colorida e textura \u00e9 importante. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness https://arxiv.org/abs/1811.12231","title":"02-TransferLearningSimples-vazio"},{"location":"notebooks/#02b-transferlearningsimplesregularizer-vazio","text":"02b-TransferLearningSimplesRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. N\u00e3o houve sucesso neste treinamento, necess\u00e1rio debugar posteriormente","title":"02b-TransferLearningSimplesRegularizer-vazio"},{"location":"notebooks/#02c-transferlearning-featureextractionregularizer-vazio","text":"02c-TransferLearningSimplesFeatureExtractionRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. acc: 0.9408 - val_acc: 0.9514 Neste caso, se optou por utilizar as camadas pr\u00e9 treinadas para feature extraction, e, foi utilizada Max Pooling na \u00faltima camada em vez de Avg Pooling. Observa\u00e7\u00f5es: Ap\u00f3s a extra\u00e7\u00e3o das features das imagens, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, a extra\u00e7\u00e3o separada dos features permitir\u00e1 treinar v\u00e1rios classificadores, fazer grid search e cross validation, entre outros. Conforme demonstrado acima, h\u00e1 entre as imagens da classe nvazio diversos exemplos que parecem da classe vazio. Ou s\u00e3o erros de base ou s\u00e3o exemplos extremamente similares aos vazios. O aprendizado deve melhorar eliminando estes da base. Ser\u00e1 criada uma c\u00f3pia da base sem esses exemplos, para testar os mesmos algoritmos e comparar.","title":"02c-TransferLearning-FeatureExtractionRegularizer-vazio"},{"location":"notebooks/#02c2-transferlearningfeatureextraction-vazio","text":"02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" (teste 01b3) produzida por 02c e o2d2 Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Base original maxpool: acc: 0.9604 - val_acc: 0.9566 Base original avgpool: acc: 0.9594 - val_acc: 0.9588 Parece que n\u00e3o importa o que se tente, h\u00e1 um plat\u00f4 em torno de 0.96 para accuracy na base original. Com a base \"limpa\" de alguns erros de rotulagem, foi poss\u00edvel subir este plat\u00f4 para um pouco mais de 97%. Como a maioria dos erros \u00e9 na classe vazio, antes de prosseguir: * Testar neste mesmo notebook treinamento com class_weigth * Copiar este notebook e repetir mesmos passos na base gerada por 02d2 O uso de class_weight 3 para a classe 0 (n\u00e3o vazio) causou queda marginal na accuracy total, mas distribuindo melhor os erros, conforme tabela abaixo ( a accuracy caiu nas casas centesimais, em torno de 4 cent\u00e9simos): BASE TEST Sem class_weight precision recall f1-score support 0.0 0.99 0.92 0.96 1166 1.0 0.93 0.99 0.96 1138 Com class_weight precision recall f1-score support 0.0 0.97 0.94 0.95 1166 1.0 0.94 0.97 0.95 1138 BASE TRAIN Sem class_weight precision recall f1-score support 0.0 1.00 0.93 0.96 10494 1.0 0.93 1.00 0.96 10306 Com class_weight precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306","title":"02c2-TransferLearningFeatureExtraction-Vazio"},{"location":"notebooks/#02c3-transferlearningfeatureextraction-vazio","text":"02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" e filtrado (mesma base que notebook 01b3) Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Detalhes no notebook. Resumindo, os resultados foram muito similares ao notebook 01b3: aumento de 2% em accuracy em rela\u00e7\u00e3o \u00e0 base original, provavelmente pela corre\u00e7\u00e3o de erros de r\u00f3tulo De resto, resultados similares ao notebook 02c2, em todas as tabelas (com o aumento de quase 2%)","title":"02c3-TransferLearningFeatureExtraction-Vazio"},{"location":"notebooks/#02d-auxiliar-imageaugmentation-vazios","text":"02d-auxiliar-ImageAugmentation-Vazios Notebook auxiliar para gerar uma base aumentada.","title":"02d-auxiliar-ImageAugmentation-Vazios"},{"location":"notebooks/#02d2-auxiliar-imageaugmentationmenostransfom-vazios","text":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es.","title":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios"},{"location":"notebooks/#02d2-auxiliar-imageaugmentationmenostransfom-vazios_1","text":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es.","title":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios"},{"location":"notebooks/#observacoes","text":"Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpoll nos resultados e menor tempo de converg\u00eancia.","title":"Observa\u00e7\u00f5es"},{"location":"sobre/","text":"Desenvolvido na RFB dentro do escopo do Sistema AJNA Ivan da Silva Bras\u00edlico C\u00f3digo Fonte no GitHub Apresentado como Capstone Project no curso de Engenheiro de Machine Learning, Udacity.","title":"Sobre"},{"location":"sobre/#desenvolvido-na-rfb-dentro-do-escopo-do-sistema-ajna","text":"Ivan da Silva Bras\u00edlico C\u00f3digo Fonte no GitHub Apresentado como Capstone Project no curso de Engenheiro de Machine Learning, Udacity.","title":"Desenvolvido na RFB dentro do escopo do Sistema AJNA"}]}