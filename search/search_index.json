{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Vis\u00e3o computacional com Redes Convolucionais Classifica\u00e7\u00e3o, busca, simillaridade, reutiliza\u00e7\u00e3o de extra\u00e7\u00e3o de caracter\u00edsticas Ivan da Silva Bras\u00edlico 2019-07-19 Notas para a visualiza\u00e7\u00e3o em PDF O site https://ivanbrasilico.github.io/model_ajna_1/ permite uma melhor navega\u00e7\u00e3o e visualiza\u00e7\u00e3o mais completa, incluindo c\u00f3pia HTML de todos os notebooks. O c\u00f3digo-fonte completo do projeto est\u00e1 no GitHub: https://github.com/IvanBrasilico/model_ajna_1 Vis\u00e3o geral Nestes documentos est\u00e3o centralizadas as anota\u00e7\u00f5es e hist\u00f3rico detalhado do treinamento e testes de alguns modelos de vis\u00e3o computacional. Ser\u00e3o avaliadas as mesmas t\u00e9cnicas em bases diferentes, para efeito de compara\u00e7\u00e3o. Linhas gerais: Baixar a base chestXRay Gerar e baixar base de Vazios e NcmsUnicos projeto AJNA Rodar treinamento e testes com modelo convolucional simples Rodar treinamento e testes com modelo \"State of the Art\" - Pesos do Imagenet Rodar treinamento e testes de extra\u00e7\u00e3o de caracter\u00edsticas para classifica\u00e7\u00e3o Fazer teste de extra\u00e7\u00e3o de caracter\u00edsticas para busca de similaridade Rodar treinamento e testes usando redes siamesas Fazer teste de extra\u00e7\u00e3o de caracter\u00edsticas com redes siamesas para busca de similaridade Autoencoders, clusteriza\u00e7\u00e3o, para busca Organiza\u00e7\u00e3o Proposta do projeto - Capstone Proposal Relat\u00f3rio resumido Relat\u00f3rio com detalhes da explora\u00e7\u00e3o de dados, modelos desenvolvidos, testes e itera\u00e7\u00f5es Conclus\u00f5es finais C\u00f3digo Fonte do Projeto O trabalho foi dividido em v\u00e1rios notebooks para melhor organiza\u00e7\u00e3o. Estes notebooks est\u00e3o com a seguinte nomenclatura <n\u00famero sequencial t\u00e9cnica/modelo><refinamento>-<descricao>-<base> Ex: 01 - n\u00famero sequencial b - refinamento Transfer Learning - t\u00e9cnica vazios - base de dados Assim: 01-RedeSimples-chestXRay \u00e9 uma rede neural simples para classificar a base chestXRay 01-RedeSimples-vazios \u00e9 uma rede neural simples para classificar a base vazios 01b-RedeSimples-vazios \u00e9 a mesma rede/t\u00e9cnica do 01 mas com algumas modifica\u00e7\u00f5es Descri\u00e7\u00e3o do problema e das bases Conforme detalhado em CapstoneProject, ser\u00e3o treinadas redes convolucionais simples do zero, modelos sofisticados com transfer learning, e redes siamesas. As bases utilizadas ser\u00e3o chestXRay, vazios e ncmsunicos. Al\u00e9m da tarefa de classifica\u00e7\u00e3o, o objetivo do projeto \u00e9 tentar, com reaproveitamento, reutilizar artefatos obtidos em novas classifica\u00e7\u00f5es e tamb\u00e9m validar o uso para agrupamento e similaridade. Assim, ser\u00e1 poss\u00edvel economizar recurso computacional e humano em um ambiente de produ\u00e7\u00e3o. Adicionalmente, uma tend\u00eancia atual da IA \u00e9 a busca de \"Sistemas de Intelig\u00eancia Aumentada\", ou IA \"Centauro\". Assim, os algoritmos s\u00e3o utilizados para empoderar operadores humanos. Com isso, al\u00e9m da classifica\u00e7\u00e3o, prover agrupamento e busca de casos similares pode aumentar o poder de operadores humanos. Como exemplo, um m\u00e9dico pode procurar pacientes com casos similares para comparar prontu\u00e1rios e tratamentos, ou um analista de risco pode buscar imagens de escaneamento similares no rastro de uma fraude. M\u00e9tricas Utilizando as defini\u00e7\u00f5es de Andrew Ng em deeplearning.ai, primeiramente tentaremos definir um erro \"aceit\u00e1vel\". Para isso, ser\u00e1 estimado o erro humano, em seguida ser\u00e1 avaliado o erro de um modelo baseline e avaliados visualmente os erros cometidos. Primeiramente ser\u00e1 avaliada o acerto geral do modelo na base treinamento ( accuracy ), mas vigiando sempre a fun\u00e7\u00e3o custo ( loss ) e tamb\u00e9m os equivalentes na base validation ( val_loss e val_accuracy ). Assim, primeiramente se ter\u00e1 como meta a redu\u00e7\u00e3o do \"bias evit\u00e1vel\" e ter certeza de estar com um modelo promissor. Em seguida ser\u00e1 avaliada a vari\u00e2ncia e sobreajuste, isso \u00e9, se o \"gap\" entre acc e val_acc \u00e9 alto. Caso sejam, ser\u00e1 avaliado se \u00e9 um problema de sobreajuste ou um v\u00edcio/erro nas bases de dados. A accuracy (termo sem tradu\u00e7\u00e3o exata para o Portugu\u00eas exceto o neologismo acur\u00e1cia, podendo ser traduzido tamb\u00e9m para exatid\u00e3o) mede de todas as previs\u00f5es realizadas, a porcentagem de acertos, isto \u00e9: total de previs\u00f5es corretas / total de previs\u00f5es Ap\u00f3s esta primeira fase, passar\u00e1 a se olhar tamb\u00e9m outras m\u00e9tricas (precis\u00e3o, recall e f1-score ) de uma das classes ou das duas, conforme for mais importante para a vis\u00e3o de neg\u00f3cio. A diferen\u00e7a das m\u00e9tricas precis\u00e3o e recall para accuracy simples necessita entendimento do conceito de falso positivo e falso negativo. Assim, do total de exemplos da base submetidos ao modelo, podemos dividir por classe numa matriz de confus\u00e3o. A matriz de confus\u00e3o bin\u00e1ria tem a seguinte configura\u00e7\u00e3o(considerando que fixamos POSITIVO como a classe 1): Valores reais Classe 0 Classe 1 Valores preditivos Classe 0 TN FN Classe 1 FP TP Assim: TP - True Positive \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 1 e foram classificados na classe 1 corretamente pelo modelo (classe 1 \u00e9, por exemplo, PNEUMONIA na nossa base chestXRay) TN - True Negative \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 0 e foram classificados na classe 0 corretamente pelo modelo (classe 0 \u00e9, por exemplo, NORMAL na nossa base chestXRay) FP - False Positive \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 0 e foram classificados na classe 1 incorretamente pelo modelo - seriam os \"alarmes falsos\", pessoas sem pneumonia que foram classificadas como contendo pneumonia. FN - False Negative \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 1 (Positivo para PNEUMONIA) e foram classificados na classe 0 incorretamente pelo modelo - seriam pessoas com pneumonia que o nosso modelo mandaria para caso, sem tratamento e com risco \u00e0 sua sa\u00fade e at\u00e9 risco de morte. Assim, seria melhor que nossos erros fossem concentrados no tipo FP - melhor mandar um paciente saud\u00e1vel para o m\u00e9dico revisar o exame do que mandar o paciente doente para casa sem o m\u00e9dico analisar mais a fundo. Precisamos minimizar o erro FN mesmo que isso custe diminuir um pouco o accuracy . A isso chamamos Recall ou recupera\u00e7\u00e3o: percentual do total de pacientes doentes detectados. Na tabela apresentada, matematicamente \u00e9 TP / TP + FN. Se FN = 0 Recall \u00e9 100%. Precis\u00e3o \u00e9 a quantidade de acertos quando o modelo detecta positivo na classe 1, ou TP / TP + FP. Note-se que caso se inverta a defini\u00e7\u00e3o de \"Positivo\", o recall e precis\u00e3o mudam, sendo quase trocados um pelo outro se a base \u00e9 balanceada. Deve ser evitada esta confus\u00e3o quando desta avalia\u00e7\u00e3o, por isso \u00e9 importante deixar claro que a maximiza\u00e7\u00e3o de recall \u00e9 para a detec\u00e7\u00e3o da classe 1 - PNEUMONIA. Normalmente, todo modelo tem algum erro, e esse erro pode ser direcionado atrav\u00e9s de t\u00e9cnicas como Image Augmentation, peso de classes ou mudan\u00e7a de threshold. E h\u00e1 um tradeoff entre precis\u00e3o e recall , quando um aumenta e outro diminui. Para medir o equil\u00edbrio entre estas duas m\u00e9tricas, pode ser monitorado tamb\u00e9m o f1-score, que \u00e9 a m\u00e9dia harm\u00f4nica entre Precis\u00e3o e Recall Como o projeto visa permitir reaproveitamento dos artefatos gerados e tamb\u00e9m gerar \u00edndices de similaridade para busca, ser\u00e3o avaliados tamb\u00e9m uso de disco, mem\u00f3ria e velocidade de cada modelo. Adicionalmente, para m\u00e9trica de busca por similaridade, ser\u00e1 utilizada avalia\u00e7\u00e3o visual pela escolha rand\u00f4mica de alguns exemplos e se o r\u00f3tulo \u00e9 coincidente para os primeiros resultados de uma busca por similaridade.","title":"Defini\u00e7\u00e3o"},{"location":"#visao-computacional-com-redes-convolucionais","text":"","title":"Vis\u00e3o computacional com Redes Convolucionais"},{"location":"#classificacao-busca-simillaridade-reutilizacao-de-extracao-de-caracteristicas","text":"Ivan da Silva Bras\u00edlico 2019-07-19","title":"Classifica\u00e7\u00e3o, busca, simillaridade, reutiliza\u00e7\u00e3o de extra\u00e7\u00e3o de caracter\u00edsticas"},{"location":"#notas-para-a-visualizacao-em-pdf","text":"O site https://ivanbrasilico.github.io/model_ajna_1/ permite uma melhor navega\u00e7\u00e3o e visualiza\u00e7\u00e3o mais completa, incluindo c\u00f3pia HTML de todos os notebooks. O c\u00f3digo-fonte completo do projeto est\u00e1 no GitHub: https://github.com/IvanBrasilico/model_ajna_1","title":"Notas para a visualiza\u00e7\u00e3o em PDF"},{"location":"#visao-geral","text":"Nestes documentos est\u00e3o centralizadas as anota\u00e7\u00f5es e hist\u00f3rico detalhado do treinamento e testes de alguns modelos de vis\u00e3o computacional. Ser\u00e3o avaliadas as mesmas t\u00e9cnicas em bases diferentes, para efeito de compara\u00e7\u00e3o. Linhas gerais: Baixar a base chestXRay Gerar e baixar base de Vazios e NcmsUnicos projeto AJNA Rodar treinamento e testes com modelo convolucional simples Rodar treinamento e testes com modelo \"State of the Art\" - Pesos do Imagenet Rodar treinamento e testes de extra\u00e7\u00e3o de caracter\u00edsticas para classifica\u00e7\u00e3o Fazer teste de extra\u00e7\u00e3o de caracter\u00edsticas para busca de similaridade Rodar treinamento e testes usando redes siamesas Fazer teste de extra\u00e7\u00e3o de caracter\u00edsticas com redes siamesas para busca de similaridade Autoencoders, clusteriza\u00e7\u00e3o, para busca","title":"Vis\u00e3o geral"},{"location":"#organizacao","text":"Proposta do projeto - Capstone Proposal Relat\u00f3rio resumido Relat\u00f3rio com detalhes da explora\u00e7\u00e3o de dados, modelos desenvolvidos, testes e itera\u00e7\u00f5es Conclus\u00f5es finais C\u00f3digo Fonte do Projeto O trabalho foi dividido em v\u00e1rios notebooks para melhor organiza\u00e7\u00e3o. Estes notebooks est\u00e3o com a seguinte nomenclatura <n\u00famero sequencial t\u00e9cnica/modelo><refinamento>-<descricao>-<base> Ex: 01 - n\u00famero sequencial b - refinamento Transfer Learning - t\u00e9cnica vazios - base de dados Assim: 01-RedeSimples-chestXRay \u00e9 uma rede neural simples para classificar a base chestXRay 01-RedeSimples-vazios \u00e9 uma rede neural simples para classificar a base vazios 01b-RedeSimples-vazios \u00e9 a mesma rede/t\u00e9cnica do 01 mas com algumas modifica\u00e7\u00f5es","title":"Organiza\u00e7\u00e3o"},{"location":"#descricao-do-problema-e-das-bases","text":"Conforme detalhado em CapstoneProject, ser\u00e3o treinadas redes convolucionais simples do zero, modelos sofisticados com transfer learning, e redes siamesas. As bases utilizadas ser\u00e3o chestXRay, vazios e ncmsunicos. Al\u00e9m da tarefa de classifica\u00e7\u00e3o, o objetivo do projeto \u00e9 tentar, com reaproveitamento, reutilizar artefatos obtidos em novas classifica\u00e7\u00f5es e tamb\u00e9m validar o uso para agrupamento e similaridade. Assim, ser\u00e1 poss\u00edvel economizar recurso computacional e humano em um ambiente de produ\u00e7\u00e3o. Adicionalmente, uma tend\u00eancia atual da IA \u00e9 a busca de \"Sistemas de Intelig\u00eancia Aumentada\", ou IA \"Centauro\". Assim, os algoritmos s\u00e3o utilizados para empoderar operadores humanos. Com isso, al\u00e9m da classifica\u00e7\u00e3o, prover agrupamento e busca de casos similares pode aumentar o poder de operadores humanos. Como exemplo, um m\u00e9dico pode procurar pacientes com casos similares para comparar prontu\u00e1rios e tratamentos, ou um analista de risco pode buscar imagens de escaneamento similares no rastro de uma fraude.","title":"Descri\u00e7\u00e3o do problema e das bases"},{"location":"#metricas","text":"Utilizando as defini\u00e7\u00f5es de Andrew Ng em deeplearning.ai, primeiramente tentaremos definir um erro \"aceit\u00e1vel\". Para isso, ser\u00e1 estimado o erro humano, em seguida ser\u00e1 avaliado o erro de um modelo baseline e avaliados visualmente os erros cometidos. Primeiramente ser\u00e1 avaliada o acerto geral do modelo na base treinamento ( accuracy ), mas vigiando sempre a fun\u00e7\u00e3o custo ( loss ) e tamb\u00e9m os equivalentes na base validation ( val_loss e val_accuracy ). Assim, primeiramente se ter\u00e1 como meta a redu\u00e7\u00e3o do \"bias evit\u00e1vel\" e ter certeza de estar com um modelo promissor. Em seguida ser\u00e1 avaliada a vari\u00e2ncia e sobreajuste, isso \u00e9, se o \"gap\" entre acc e val_acc \u00e9 alto. Caso sejam, ser\u00e1 avaliado se \u00e9 um problema de sobreajuste ou um v\u00edcio/erro nas bases de dados. A accuracy (termo sem tradu\u00e7\u00e3o exata para o Portugu\u00eas exceto o neologismo acur\u00e1cia, podendo ser traduzido tamb\u00e9m para exatid\u00e3o) mede de todas as previs\u00f5es realizadas, a porcentagem de acertos, isto \u00e9: total de previs\u00f5es corretas / total de previs\u00f5es Ap\u00f3s esta primeira fase, passar\u00e1 a se olhar tamb\u00e9m outras m\u00e9tricas (precis\u00e3o, recall e f1-score ) de uma das classes ou das duas, conforme for mais importante para a vis\u00e3o de neg\u00f3cio. A diferen\u00e7a das m\u00e9tricas precis\u00e3o e recall para accuracy simples necessita entendimento do conceito de falso positivo e falso negativo. Assim, do total de exemplos da base submetidos ao modelo, podemos dividir por classe numa matriz de confus\u00e3o. A matriz de confus\u00e3o bin\u00e1ria tem a seguinte configura\u00e7\u00e3o(considerando que fixamos POSITIVO como a classe 1): Valores reais Classe 0 Classe 1 Valores preditivos Classe 0 TN FN Classe 1 FP TP Assim: TP - True Positive \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 1 e foram classificados na classe 1 corretamente pelo modelo (classe 1 \u00e9, por exemplo, PNEUMONIA na nossa base chestXRay) TN - True Negative \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 0 e foram classificados na classe 0 corretamente pelo modelo (classe 0 \u00e9, por exemplo, NORMAL na nossa base chestXRay) FP - False Positive \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 0 e foram classificados na classe 1 incorretamente pelo modelo - seriam os \"alarmes falsos\", pessoas sem pneumonia que foram classificadas como contendo pneumonia. FN - False Negative \u00e9 a quantidade de exemplos que est\u00e3o rotulados na classe 1 (Positivo para PNEUMONIA) e foram classificados na classe 0 incorretamente pelo modelo - seriam pessoas com pneumonia que o nosso modelo mandaria para caso, sem tratamento e com risco \u00e0 sua sa\u00fade e at\u00e9 risco de morte. Assim, seria melhor que nossos erros fossem concentrados no tipo FP - melhor mandar um paciente saud\u00e1vel para o m\u00e9dico revisar o exame do que mandar o paciente doente para casa sem o m\u00e9dico analisar mais a fundo. Precisamos minimizar o erro FN mesmo que isso custe diminuir um pouco o accuracy . A isso chamamos Recall ou recupera\u00e7\u00e3o: percentual do total de pacientes doentes detectados. Na tabela apresentada, matematicamente \u00e9 TP / TP + FN. Se FN = 0 Recall \u00e9 100%. Precis\u00e3o \u00e9 a quantidade de acertos quando o modelo detecta positivo na classe 1, ou TP / TP + FP. Note-se que caso se inverta a defini\u00e7\u00e3o de \"Positivo\", o recall e precis\u00e3o mudam, sendo quase trocados um pelo outro se a base \u00e9 balanceada. Deve ser evitada esta confus\u00e3o quando desta avalia\u00e7\u00e3o, por isso \u00e9 importante deixar claro que a maximiza\u00e7\u00e3o de recall \u00e9 para a detec\u00e7\u00e3o da classe 1 - PNEUMONIA. Normalmente, todo modelo tem algum erro, e esse erro pode ser direcionado atrav\u00e9s de t\u00e9cnicas como Image Augmentation, peso de classes ou mudan\u00e7a de threshold. E h\u00e1 um tradeoff entre precis\u00e3o e recall , quando um aumenta e outro diminui. Para medir o equil\u00edbrio entre estas duas m\u00e9tricas, pode ser monitorado tamb\u00e9m o f1-score, que \u00e9 a m\u00e9dia harm\u00f4nica entre Precis\u00e3o e Recall Como o projeto visa permitir reaproveitamento dos artefatos gerados e tamb\u00e9m gerar \u00edndices de similaridade para busca, ser\u00e3o avaliados tamb\u00e9m uso de disco, mem\u00f3ria e velocidade de cada modelo. Adicionalmente, para m\u00e9trica de busca por similaridade, ser\u00e1 utilizada avalia\u00e7\u00e3o visual pela escolha rand\u00f4mica de alguns exemplos e se o r\u00f3tulo \u00e9 coincidente para os primeiros resultados de uma busca por similaridade.","title":"M\u00e9tricas"},{"location":"conclusao/","text":"Conclus\u00f5es Observa\u00e7\u00f5es Foram utilizadas v\u00e1rias t\u00e9cnicas e realizadas diversas itera\u00e7\u00f5es/melhorias dentro das t\u00e9cnicas, sucessivamente. Al\u00e9m disso, paralelamente, testes parecidos foram realizados em bases diferentes para testar generalidade do modelo. Base ChestXRay Conforme era esperado, esta base se mostrou mais dif\u00edcil de trabalhar do que a base de escaneamento de cont\u00eaineres para classificar vazio/ n\u00e3o vazio Considerou-se que para este tipo de problema o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 A diferen\u00e7a entre treinamento e valida\u00e7\u00e3o demonstra uma vari\u00e2ncia grande, mas pelos testes na base seria importante checar se n\u00e3o se trata de um data mismatch . Esta base parece ter problemas de balanceamento e tamb\u00e9m de distribui\u00e7\u00e3o. Como pr\u00f3ximo passo, seria interessante fundir todos os exemplos da base orginal (train, val, test) em uma base \u00fanica e fazer um resample das bases de treinamento e valida\u00e7\u00e3o, rodando c\u00f3pias destes notebooks e comparando os resultados. Al\u00e9m disso, testar t\u00e9cnicas adicionais de image augmentation e balanceamento de classes (par\u00e2metro class weight ou aumento de uma categoria). Base Vazios Nesta base tamb\u00e9m considerou-se que o mais importante seria obter um recall alto, reconhecendo principalmente cont\u00eaineres declarados como vazios mas contendo carga. Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpool nos resultados e menor tempo de converg\u00eancia. Os melhores resultados obtidos foram de 96% de accuracy e 96% de f1-score, sendo que a base parece ter em torno de 2% de erros de rotulagem. Com a base limpa, o resultado subiu a quase 98%. Embora pela visualiza\u00e7\u00e3o haja espa\u00e7o para melhora (alguns cont\u00eaineres n\u00e3o vazios com muito pouca carga mas facilmente identifi\u00e1veis pelo olho humano classificados como vazios), o modelo est\u00e1 muito pr\u00f3ximo de um candidato a coloca\u00e7\u00e3o em produ\u00e7\u00e3o. Outro ponto interessante \u00e9 que foi demostrado ser poss\u00edvel utilizar um classificador extremamente simples e r\u00e1pido, que utiliza como ponto de entrada apenas 1024 n\u00fameros que podem ser pr\u00e9-extra\u00eddos das imagens pela rede DenseNet121 e ocupa apenas 14MB de RAM por batch. Neste problema, a rede Siamesa treinada tamb\u00e9m apresentou resultados excelentes. Utilizar redes siamesas para classifica\u00e7\u00e3o adiciona uma complexidade: como a rede sempre compara duas imagens, n\u00e3o h\u00e1 uma rede treinada para simplesmente fazer a classifica\u00e7\u00e3o da imagem, mas sim dar um n\u00famero (pr\u00f3ximo de zero para itens iguais ou da mesma classe, pr\u00f3ximo de 1 para itens diferentes). Optou-se por comparar a imagem a ser classificada com duas imagens: uma da classe 0 e outra da classe1. A que retornar menor n\u00famero \u00e9 considerada a correta. Baseline SVM precision recall f1-score support 0 1.0000 0.9117 0.9538 1166 1 0.9179 1.0000 0.9572 1151 Rede 01b3 (baseline simples) precision recall f1-score support 0 1.0000 0.9245 0.9608 1166 1 0.9290 1.0000 0.9632 1151 Rede 02c3 ( Features da DenseNet121 treinada na Imagenet) precision recall f1-score support 0 0.9900 0.9297 0.9589 1166 1 0.9329 0.9904 0.9608 1151 Rede Siamesa precision recall f1-score support 0.0 0.9972 0.9228 0.9586 1166 1.0 0.9273 0.9974 0.9611 1151 Mais do que apenas ver os n\u00fameros, seria interessante visualizar e entender os erros que cada modelo est\u00e1 cometendo. Assim, no notebook 05 comparei tamb\u00e9m os erros de cada modelo entre si. A diverg\u00eancia maior foi entre o modelo 1 e os demais, chegando a 3%. Os modelos de redes neurais possuem menos de 1,5% de diverg\u00eancia entre os erros e acertos. Isso indica comprova\u00e7\u00e3o parcial da teoria de que: 1. H\u00e1 erros de r\u00f3tulo, 2. H\u00e1 exemplos muito dif\u00edceis ou no limiar. Para lembrar, no in\u00edcio do treinamento o modelo cometia erros como os abaixo, classificando cont\u00eaineres claramente n\u00e3o vazios como vazios, mas com probabilidade baixa (65% ou menos, sendo que 50% \u00e9 o limiar para classifica\u00e7\u00e3o na outra classe). J\u00e1 os \u00faltimos modelos est\u00e3o cometendo os erros mostrados abaixo. Note-se que o SVM comete erros \"bobos\". J\u00e1 os erros de rede neural, especialmente os com recall mais alto, quase em 100% das vezes fica dif\u00edcil de saber se \u00e9 erro de r\u00f3tulo, pois a visualiza\u00e7\u00e3o tamb\u00e9m indica um cont\u00eainer sem carga. Erros SVM Erros Rede Neural Simples Erros DenseNet Transfer Learning Erros DenseNet Transfer Learning com class weights Erros 3a Erros Siamesa Desempenho (em tempo e consumo de mem\u00f3ria) Devido \u00e0 grande dimensionalidade do problema, a solu\u00e7\u00e3o SVM ocupa bastante mem\u00f3ria e \u00e9 a que tem maior tempo de execu\u00e7\u00e3o (em computador que possui GPU, provavelmente sem GPUs as redes neurais teriam desempenho muito inferior) Em seguida a rede DenseNet pr\u00e9 treinada \u00e9 a que tem maior uso de mem\u00f3ria. A rede neural simples possui o menor uso de mem\u00f3ria de todas e maior rapidez. A rede siamesa utiliza mem\u00f3ria intermedi\u00e1ria mas se mostrou mais lenta que a rede imagenet, pois precisa extrair features de duas imagens para depois fazer compara\u00e7\u00f5es. Tempos para carregar do disco, redimensionar e fazer predic\u00f5es em 2317 imagens: Nome da t\u00e9cnica tempo Consumo de mem\u00f3ria GPU(1) Rede DenseNet121 2min 35s Alto N\u00e3o SVM 1min 37s Alto N\u00e3o Rede DenseNet121 25.2 s Alto Sim Rede neural simples 01b3 22.2 s Alto N\u00e3o Rede siamesa(2) 15.4 s M\u00e9dio Sim Rede neural simples 01b3 9.15 s M\u00e9dio-baixo Sim Tratar 1024 features(3) 43 ms Baixo N\u00e3o Tratar 1024 features(3) 126 ms Baixo Sim Tratar 128 features(3) <10 ms Muito baixo Sim GPU n\u00e3o \u00e9 estritamente necess\u00e1ria para predi\u00e7\u00e3o de redes neurais, mas em uma predi\u00e7\u00e3o de rede neural, especialmente uma rede convolucional, o tempo \u00e9 muito maior sem utiliza\u00e7\u00e3o de GPU. Para este teste foi utilizada CPU Intel i5 com 2.30ghz e 8 cores, cache L1 32K, L1 256K e L3 8192K e NUMA mode. A GPU utilizada foi uma GTX1050ti 4GB, cuda 10.1. Mem\u00f3ria do Sistema de 8GB. A rede siamesa precisa sempre passar duas imagens, por isso o tempo \u00e9 maior que 01b3. Para melhorar a precis\u00e3o, poderiam ser comparadas v\u00e1rios pares de imagens, e os tempos ser\u00e3o somados Desde o come\u00e7o do projeto uma das id\u00e9ias que saem do padr\u00e3o de simplesmente treinar um classificador do in\u00edco ao fim \u00e9 reutilizar os aprendizados de uma etapa em outra. Assim, caso as imagens estejam em uma base centralizada, uma boa pr\u00e1tica que quase nunca \u00e9 vista nos papers ou tutoriais seria fazer pr\u00e9 extra\u00e7\u00e3o de features em batch e utilizar, posteriormente, estas features ao inv\u00e9s de carregar a imagem original. \u00c9 uma redu\u00e7\u00e3o entre 2.400 a 20.000 vezes (de uma imagem SVGA para 1.024 ou 128 floats por exemplo). Assim, economiza-se disco, I/O, processamento, mem\u00f3ria, energia el\u00e9trica e a redu\u00e7\u00e3o dr\u00e1stica do tempo de processamento possibilita inclusive fazer tarefas muito mais complexas, como uma busca de similaridade em todo o banco de dados ou agrupamento (clusteriza\u00e7\u00e3o) das imagens.","title":"Conclus\u00f5es"},{"location":"conclusao/#conclusoes","text":"","title":"Conclus\u00f5es"},{"location":"conclusao/#observacoes","text":"Foram utilizadas v\u00e1rias t\u00e9cnicas e realizadas diversas itera\u00e7\u00f5es/melhorias dentro das t\u00e9cnicas, sucessivamente. Al\u00e9m disso, paralelamente, testes parecidos foram realizados em bases diferentes para testar generalidade do modelo.","title":"Observa\u00e7\u00f5es"},{"location":"conclusao/#base-chestxray","text":"Conforme era esperado, esta base se mostrou mais dif\u00edcil de trabalhar do que a base de escaneamento de cont\u00eaineres para classificar vazio/ n\u00e3o vazio Considerou-se que para este tipo de problema o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 A diferen\u00e7a entre treinamento e valida\u00e7\u00e3o demonstra uma vari\u00e2ncia grande, mas pelos testes na base seria importante checar se n\u00e3o se trata de um data mismatch . Esta base parece ter problemas de balanceamento e tamb\u00e9m de distribui\u00e7\u00e3o. Como pr\u00f3ximo passo, seria interessante fundir todos os exemplos da base orginal (train, val, test) em uma base \u00fanica e fazer um resample das bases de treinamento e valida\u00e7\u00e3o, rodando c\u00f3pias destes notebooks e comparando os resultados. Al\u00e9m disso, testar t\u00e9cnicas adicionais de image augmentation e balanceamento de classes (par\u00e2metro class weight ou aumento de uma categoria).","title":"Base ChestXRay"},{"location":"conclusao/#base-vazios","text":"Nesta base tamb\u00e9m considerou-se que o mais importante seria obter um recall alto, reconhecendo principalmente cont\u00eaineres declarados como vazios mas contendo carga. Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpool nos resultados e menor tempo de converg\u00eancia. Os melhores resultados obtidos foram de 96% de accuracy e 96% de f1-score, sendo que a base parece ter em torno de 2% de erros de rotulagem. Com a base limpa, o resultado subiu a quase 98%. Embora pela visualiza\u00e7\u00e3o haja espa\u00e7o para melhora (alguns cont\u00eaineres n\u00e3o vazios com muito pouca carga mas facilmente identifi\u00e1veis pelo olho humano classificados como vazios), o modelo est\u00e1 muito pr\u00f3ximo de um candidato a coloca\u00e7\u00e3o em produ\u00e7\u00e3o. Outro ponto interessante \u00e9 que foi demostrado ser poss\u00edvel utilizar um classificador extremamente simples e r\u00e1pido, que utiliza como ponto de entrada apenas 1024 n\u00fameros que podem ser pr\u00e9-extra\u00eddos das imagens pela rede DenseNet121 e ocupa apenas 14MB de RAM por batch. Neste problema, a rede Siamesa treinada tamb\u00e9m apresentou resultados excelentes. Utilizar redes siamesas para classifica\u00e7\u00e3o adiciona uma complexidade: como a rede sempre compara duas imagens, n\u00e3o h\u00e1 uma rede treinada para simplesmente fazer a classifica\u00e7\u00e3o da imagem, mas sim dar um n\u00famero (pr\u00f3ximo de zero para itens iguais ou da mesma classe, pr\u00f3ximo de 1 para itens diferentes). Optou-se por comparar a imagem a ser classificada com duas imagens: uma da classe 0 e outra da classe1. A que retornar menor n\u00famero \u00e9 considerada a correta. Baseline SVM precision recall f1-score support 0 1.0000 0.9117 0.9538 1166 1 0.9179 1.0000 0.9572 1151 Rede 01b3 (baseline simples) precision recall f1-score support 0 1.0000 0.9245 0.9608 1166 1 0.9290 1.0000 0.9632 1151 Rede 02c3 ( Features da DenseNet121 treinada na Imagenet) precision recall f1-score support 0 0.9900 0.9297 0.9589 1166 1 0.9329 0.9904 0.9608 1151 Rede Siamesa precision recall f1-score support 0.0 0.9972 0.9228 0.9586 1166 1.0 0.9273 0.9974 0.9611 1151 Mais do que apenas ver os n\u00fameros, seria interessante visualizar e entender os erros que cada modelo est\u00e1 cometendo. Assim, no notebook 05 comparei tamb\u00e9m os erros de cada modelo entre si. A diverg\u00eancia maior foi entre o modelo 1 e os demais, chegando a 3%. Os modelos de redes neurais possuem menos de 1,5% de diverg\u00eancia entre os erros e acertos. Isso indica comprova\u00e7\u00e3o parcial da teoria de que: 1. H\u00e1 erros de r\u00f3tulo, 2. H\u00e1 exemplos muito dif\u00edceis ou no limiar. Para lembrar, no in\u00edcio do treinamento o modelo cometia erros como os abaixo, classificando cont\u00eaineres claramente n\u00e3o vazios como vazios, mas com probabilidade baixa (65% ou menos, sendo que 50% \u00e9 o limiar para classifica\u00e7\u00e3o na outra classe). J\u00e1 os \u00faltimos modelos est\u00e3o cometendo os erros mostrados abaixo. Note-se que o SVM comete erros \"bobos\". J\u00e1 os erros de rede neural, especialmente os com recall mais alto, quase em 100% das vezes fica dif\u00edcil de saber se \u00e9 erro de r\u00f3tulo, pois a visualiza\u00e7\u00e3o tamb\u00e9m indica um cont\u00eainer sem carga. Erros SVM Erros Rede Neural Simples Erros DenseNet Transfer Learning Erros DenseNet Transfer Learning com class weights Erros 3a Erros Siamesa","title":"Base Vazios"},{"location":"conclusao/#desempenho-em-tempo-e-consumo-de-memoria","text":"Devido \u00e0 grande dimensionalidade do problema, a solu\u00e7\u00e3o SVM ocupa bastante mem\u00f3ria e \u00e9 a que tem maior tempo de execu\u00e7\u00e3o (em computador que possui GPU, provavelmente sem GPUs as redes neurais teriam desempenho muito inferior) Em seguida a rede DenseNet pr\u00e9 treinada \u00e9 a que tem maior uso de mem\u00f3ria. A rede neural simples possui o menor uso de mem\u00f3ria de todas e maior rapidez. A rede siamesa utiliza mem\u00f3ria intermedi\u00e1ria mas se mostrou mais lenta que a rede imagenet, pois precisa extrair features de duas imagens para depois fazer compara\u00e7\u00f5es. Tempos para carregar do disco, redimensionar e fazer predic\u00f5es em 2317 imagens: Nome da t\u00e9cnica tempo Consumo de mem\u00f3ria GPU(1) Rede DenseNet121 2min 35s Alto N\u00e3o SVM 1min 37s Alto N\u00e3o Rede DenseNet121 25.2 s Alto Sim Rede neural simples 01b3 22.2 s Alto N\u00e3o Rede siamesa(2) 15.4 s M\u00e9dio Sim Rede neural simples 01b3 9.15 s M\u00e9dio-baixo Sim Tratar 1024 features(3) 43 ms Baixo N\u00e3o Tratar 1024 features(3) 126 ms Baixo Sim Tratar 128 features(3) <10 ms Muito baixo Sim GPU n\u00e3o \u00e9 estritamente necess\u00e1ria para predi\u00e7\u00e3o de redes neurais, mas em uma predi\u00e7\u00e3o de rede neural, especialmente uma rede convolucional, o tempo \u00e9 muito maior sem utiliza\u00e7\u00e3o de GPU. Para este teste foi utilizada CPU Intel i5 com 2.30ghz e 8 cores, cache L1 32K, L1 256K e L3 8192K e NUMA mode. A GPU utilizada foi uma GTX1050ti 4GB, cuda 10.1. Mem\u00f3ria do Sistema de 8GB. A rede siamesa precisa sempre passar duas imagens, por isso o tempo \u00e9 maior que 01b3. Para melhorar a precis\u00e3o, poderiam ser comparadas v\u00e1rios pares de imagens, e os tempos ser\u00e3o somados Desde o come\u00e7o do projeto uma das id\u00e9ias que saem do padr\u00e3o de simplesmente treinar um classificador do in\u00edco ao fim \u00e9 reutilizar os aprendizados de uma etapa em outra. Assim, caso as imagens estejam em uma base centralizada, uma boa pr\u00e1tica que quase nunca \u00e9 vista nos papers ou tutoriais seria fazer pr\u00e9 extra\u00e7\u00e3o de features em batch e utilizar, posteriormente, estas features ao inv\u00e9s de carregar a imagem original. \u00c9 uma redu\u00e7\u00e3o entre 2.400 a 20.000 vezes (de uma imagem SVGA para 1.024 ou 128 floats por exemplo). Assim, economiza-se disco, I/O, processamento, mem\u00f3ria, energia el\u00e9trica e a redu\u00e7\u00e3o dr\u00e1stica do tempo de processamento possibilita inclusive fazer tarefas muito mais complexas, como uma busca de similaridade em todo o banco de dados ou agrupamento (clusteriza\u00e7\u00e3o) das imagens.","title":"Desempenho (em tempo e consumo de mem\u00f3ria)"},{"location":"extratores/","text":"Extratores Utiliza\u00e7\u00e3o O diret\u00f3rio extratores do projeto model_ajna_1 cont\u00e9m diversos utilit\u00e1rios e scripts para gera\u00e7\u00e3o de bases a partir do acesso ao Banco de Dados do AJNA, seja diretamente pelo MongoDB ou via API do AJNA","title":"Extratores"},{"location":"extratores/#extratores","text":"","title":"Extratores"},{"location":"extratores/#utilizacao","text":"O diret\u00f3rio extratores do projeto model_ajna_1 cont\u00e9m diversos utilit\u00e1rios e scripts para gera\u00e7\u00e3o de bases a partir do acesso ao Banco de Dados do AJNA, seja diretamente pelo MongoDB ou via API do AJNA","title":"Utiliza\u00e7\u00e3o"},{"location":"notebooks/","text":"Relat\u00f3rios da BASE ChestXRay 01-Baseline-redesimples-chestXRay 01-Baseline-redesimples-chestXRay Rede convolucional bem simples treinada do zero. Input shape = 150, 150 acc: 0.9279 - val_acc: 0.8285 01b-Baseline-redesimples-chestXRay-tamanhomaior 01b-Baseline-redesimples-chestXRay-tamanhomaior Rede convolucional bem simples treinada do zero. Treinamento em 04/09/2019: Foram realizadas v\u00e1rias rodadas(sempre continuando pesos do menor val_loss anterior): A primeira com ImageAugmentation e lr=0.001, melhor acc=0.94 e melhor val_acc=0.82 Mesmo a rede sendo simples, aparenta ligeiro overfitting A segunda com lr=0.0001 e mais \u00e9pocas para os callbacks, melhor acc=0.94 e melhor val_acc=0.83 A terceira sem ImageAugmentation, com lr muito pequena. Embora ImageAugmentation seja uma t\u00e9cnica para reduzir overfitting, e a priori tirar possa parecer contrasenso, apenas para testar se deixar a base de treinamento mais parecida com a de testes reduz erro de generaliza\u00e7\u00e3o, ao menos nesses exemplos e no \"fine tunning\" Conforme previsto pela teoria, o sobreajuste aumentou. acc foi para 0.96 e val_acc caiu para menos de 0.80 Quarta tentativa, com regulariza\u00e7\u00e3o L1 e L2 na \u00faltima camada e otimizador Adam, pareceu que ia conseguir melhoria, foi expandido o treinamento para 50 \u00e9pocas iniciando com uma lr maior, mas a melhoria foi apenas marginal, com val_acc ensaiando ultrapassar 0.87 mas oscilando bastante Em 04/06/2019 o melhor modelo foi: Epoch 14/50 acc: 0.9507 val_acc: 0.8429 Conclus\u00f5es/pr\u00f3ximos passos Tentar aumentar regulariza\u00e7\u00e3o, utilizar keras-tuner Testar modelo pr\u00e9-treinado mais poderoso (TransferLearning) Olhar exemplos de kernel no kaggle com melhor desempenho em busca de id\u00e9ias 02c-TransferLearningSimples-FeatureExtractionRegularizer-chestXRay 02c-TransferLearningSimplesFeatureExtractionRegularizer-chestXRay Utilizar DenseNet121 como feature extraction. Treinar classificador na sa\u00edda desta rede. Resultado testes: acc: 0.93 val_acc: 0.82 Pr\u00f3ximo passo: Gravar em .npy uma matriz com todas as features extra\u00eddas da base de treinamento e fazer Grid Search e Random Search do melhor classificador obtido. 02d-TransferLearning-FeatureExtraction-HyperParamTuner-chestXRay 02d-TransferLearningFeatureExtractionHyperParamTuner-chestXRay Esta rede usa como entrada uma \u00faltima camada maxpooling j\u00e1 salva, de sa\u00edda da DenseNet121 aplicada \u00e0 base de treinamento. Como todo o processamento convolucional j\u00e1 est\u00e1 realizado, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, facilita o tunning da camada classificadora. Resultado: Foi poss\u00edvel obter um classificador utilizando somente a sa\u00edda da DenseNet121 original com pesos da imagenet: Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.95 0.97 02e-auxiliar-ImageAugmentation 02e-auxiliar-ImageAugmentation Este notebook \u00e9 apenas para gerar uma base aumentada pr\u00e9-processada. Ser\u00e1 utilizado pelo outro notebook 02e. O objetivo \u00e9 tentar diminuir o sobreajuste / dist\u00e3ncia entre acc e val_acc e agilizar a fase de treinamento. 02e-FineTunning-chestXRay 02e-FineTunning-chestXRay Aqui est\u00e1 sendo treinada uma rede DenseNet121 do 02c empilhada com o classificador do 02d. Problemas: n\u00e3o ficou claro se os pesos do notebook 02d foram aproveitados. Eles s\u00e3o carregados, os testes d\u00e3o resultado similar ao 02d, mas quando inicia o treinamento de fine tunning os n\u00fameros de acc e val_acc caem pr\u00f3ximos de 0.5, para depois voltarem a subir, mesmo quando se utiliza uma lr extremamente baixa. Melhor modelo: Transfermodelweights02e_etapa2.02-0.66.hdf5 Base aumentada: acc 0.99 val_acc 0.83 Obs: Houve um problema, o acc na base train indica 99% no treinamento, mas estranhamente cai para 95% no relat\u00f3rio. Investigar. Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 03-Busca-TransferLearning-Imagenet-chestXRay 03-Busca-TransferLearning-Imagenet-chestXRay Teste do uso das features extra\u00eddas de uma rede pr\u00e9-treinada como hash para busca de similaridade. Testar atrav\u00e9s de dist\u00e2ncia euclidiana se a \u00faltima camada de rede neural DenseNet121 possui informa\u00e7\u00e3o interessante para possibilitar busca por similaridade. Foram rodadas 1.000 simula\u00e7\u00f5es aleat\u00f3rias de busca para v\u00e1rios batchs diferentes, de 512 itens para base train e 256 itens para base. No final foram rodadas 1.000 simula\u00e7\u00f5es para 10 batches da base treinamento. A avalia\u00e7\u00e3o foi realizada por coincid\u00eancia de classe nos primeiros 10 e 20 itens e tamb\u00e9m foi realizada avalia\u00e7\u00e3o visual interativa. A avalia\u00e7\u00e3o visual \u00e9 muito dif\u00edcil, precisaria de um especialista m\u00e9dico para avaliar. A avalia\u00e7\u00e3o por classe deu uma coincid\u00eancia m\u00e9dia de menos de 80%, considerada insuficiente. Tamb\u00e9m foi extra\u00edda a estat\u00edstica por classe: 0 = NORMAL 1 = PNEUMONIA Resultados utilizando MaxPooling Acerto classe 0: 53959 de 72780 (0.74) Acerto classe 1: 103373 de 127220 (0.81) Resultados utilizando AvgPooling Acerto classe 0: 55893 de 75900 (0.74) Acerto classe 1: 103782 de 124100 (0.84) Assim, as features extra\u00eddas da rede treinada na ImageNet se mostraram insuficientes para busca. N\u00e3o obstante, podem ser um ponto de partida, para treinamento de autoencoders ou outras fun\u00e7\u00f5es para gerar um hash para busca de similaridade. Observa\u00e7\u00f5es finais Considerando que para este tipo de problema o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 A diferen\u00e7a entre treinamento e valida\u00e7\u00e3o demonstra uma vari\u00e2ncia grande, mas pelos testes na base seria importante checar se n\u00e3o se trata de um data mismatch . Esta base parece ter problemas de balanceamento e tamb\u00e9m de distribui\u00e7\u00e3o. Como pr\u00f3ximo passo, seria interessante fundir todos os exemplos da base orginal (train, val, test) em uma base \u00fanica e fazer um resample das bases de treinamento e valida\u00e7\u00e3o, rodando c\u00f3pias destes notebooks e comparando os resultados. Al\u00e9m disso, testar t\u00e9cnicas adicionais de image augmentation e balanceamento de classes (par\u00e2metro class weight ou aumento de uma categoria).","title":"Relat\u00f3rio ChestXRay"},{"location":"notebooks/#relatorios-da-base-chestxray","text":"","title":"Relat\u00f3rios da BASE ChestXRay"},{"location":"notebooks/#01-baseline-redesimples-chestxray","text":"01-Baseline-redesimples-chestXRay Rede convolucional bem simples treinada do zero. Input shape = 150, 150 acc: 0.9279 - val_acc: 0.8285","title":"01-Baseline-redesimples-chestXRay"},{"location":"notebooks/#01b-baseline-redesimples-chestxray-tamanhomaior","text":"01b-Baseline-redesimples-chestXRay-tamanhomaior Rede convolucional bem simples treinada do zero. Treinamento em 04/09/2019: Foram realizadas v\u00e1rias rodadas(sempre continuando pesos do menor val_loss anterior): A primeira com ImageAugmentation e lr=0.001, melhor acc=0.94 e melhor val_acc=0.82 Mesmo a rede sendo simples, aparenta ligeiro overfitting A segunda com lr=0.0001 e mais \u00e9pocas para os callbacks, melhor acc=0.94 e melhor val_acc=0.83 A terceira sem ImageAugmentation, com lr muito pequena. Embora ImageAugmentation seja uma t\u00e9cnica para reduzir overfitting, e a priori tirar possa parecer contrasenso, apenas para testar se deixar a base de treinamento mais parecida com a de testes reduz erro de generaliza\u00e7\u00e3o, ao menos nesses exemplos e no \"fine tunning\" Conforme previsto pela teoria, o sobreajuste aumentou. acc foi para 0.96 e val_acc caiu para menos de 0.80 Quarta tentativa, com regulariza\u00e7\u00e3o L1 e L2 na \u00faltima camada e otimizador Adam, pareceu que ia conseguir melhoria, foi expandido o treinamento para 50 \u00e9pocas iniciando com uma lr maior, mas a melhoria foi apenas marginal, com val_acc ensaiando ultrapassar 0.87 mas oscilando bastante Em 04/06/2019 o melhor modelo foi: Epoch 14/50 acc: 0.9507 val_acc: 0.8429 Conclus\u00f5es/pr\u00f3ximos passos Tentar aumentar regulariza\u00e7\u00e3o, utilizar keras-tuner Testar modelo pr\u00e9-treinado mais poderoso (TransferLearning) Olhar exemplos de kernel no kaggle com melhor desempenho em busca de id\u00e9ias","title":"01b-Baseline-redesimples-chestXRay-tamanhomaior"},{"location":"notebooks/#02c-transferlearningsimples-featureextractionregularizer-chestxray","text":"02c-TransferLearningSimplesFeatureExtractionRegularizer-chestXRay Utilizar DenseNet121 como feature extraction. Treinar classificador na sa\u00edda desta rede. Resultado testes: acc: 0.93 val_acc: 0.82 Pr\u00f3ximo passo: Gravar em .npy uma matriz com todas as features extra\u00eddas da base de treinamento e fazer Grid Search e Random Search do melhor classificador obtido.","title":"02c-TransferLearningSimples-FeatureExtractionRegularizer-chestXRay"},{"location":"notebooks/#02d-transferlearning-featureextraction-hyperparamtuner-chestxray","text":"02d-TransferLearningFeatureExtractionHyperParamTuner-chestXRay Esta rede usa como entrada uma \u00faltima camada maxpooling j\u00e1 salva, de sa\u00edda da DenseNet121 aplicada \u00e0 base de treinamento. Como todo o processamento convolucional j\u00e1 est\u00e1 realizado, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, facilita o tunning da camada classificadora. Resultado: Foi poss\u00edvel obter um classificador utilizando somente a sa\u00edda da DenseNet121 original com pesos da imagenet: Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.95 0.97","title":"02d-TransferLearning-FeatureExtraction-HyperParamTuner-chestXRay"},{"location":"notebooks/#02e-auxiliar-imageaugmentation","text":"02e-auxiliar-ImageAugmentation Este notebook \u00e9 apenas para gerar uma base aumentada pr\u00e9-processada. Ser\u00e1 utilizado pelo outro notebook 02e. O objetivo \u00e9 tentar diminuir o sobreajuste / dist\u00e3ncia entre acc e val_acc e agilizar a fase de treinamento.","title":"02e-auxiliar-ImageAugmentation"},{"location":"notebooks/#02e-finetunning-chestxray","text":"02e-FineTunning-chestXRay Aqui est\u00e1 sendo treinada uma rede DenseNet121 do 02c empilhada com o classificador do 02d. Problemas: n\u00e3o ficou claro se os pesos do notebook 02d foram aproveitados. Eles s\u00e3o carregados, os testes d\u00e3o resultado similar ao 02d, mas quando inicia o treinamento de fine tunning os n\u00fameros de acc e val_acc caem pr\u00f3ximos de 0.5, para depois voltarem a subir, mesmo quando se utiliza uma lr extremamente baixa. Melhor modelo: Transfermodelweights02e_etapa2.02-0.66.hdf5 Base aumentada: acc 0.99 val_acc 0.83 Obs: Houve um problema, o acc na base train indica 99% no treinamento, mas estranhamente cai para 95% no relat\u00f3rio. Investigar. Base original: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97","title":"02e-FineTunning-chestXRay"},{"location":"notebooks/#03-busca-transferlearning-imagenet-chestxray","text":"03-Busca-TransferLearning-Imagenet-chestXRay Teste do uso das features extra\u00eddas de uma rede pr\u00e9-treinada como hash para busca de similaridade. Testar atrav\u00e9s de dist\u00e2ncia euclidiana se a \u00faltima camada de rede neural DenseNet121 possui informa\u00e7\u00e3o interessante para possibilitar busca por similaridade. Foram rodadas 1.000 simula\u00e7\u00f5es aleat\u00f3rias de busca para v\u00e1rios batchs diferentes, de 512 itens para base train e 256 itens para base. No final foram rodadas 1.000 simula\u00e7\u00f5es para 10 batches da base treinamento. A avalia\u00e7\u00e3o foi realizada por coincid\u00eancia de classe nos primeiros 10 e 20 itens e tamb\u00e9m foi realizada avalia\u00e7\u00e3o visual interativa. A avalia\u00e7\u00e3o visual \u00e9 muito dif\u00edcil, precisaria de um especialista m\u00e9dico para avaliar. A avalia\u00e7\u00e3o por classe deu uma coincid\u00eancia m\u00e9dia de menos de 80%, considerada insuficiente. Tamb\u00e9m foi extra\u00edda a estat\u00edstica por classe: 0 = NORMAL 1 = PNEUMONIA Resultados utilizando MaxPooling Acerto classe 0: 53959 de 72780 (0.74) Acerto classe 1: 103373 de 127220 (0.81) Resultados utilizando AvgPooling Acerto classe 0: 55893 de 75900 (0.74) Acerto classe 1: 103782 de 124100 (0.84) Assim, as features extra\u00eddas da rede treinada na ImageNet se mostraram insuficientes para busca. N\u00e3o obstante, podem ser um ponto de partida, para treinamento de autoencoders ou outras fun\u00e7\u00f5es para gerar um hash para busca de similaridade.","title":"03-Busca-TransferLearning-Imagenet-chestXRay"},{"location":"notebooks/#observacoes-finais","text":"Considerando que para este tipo de problema o mais importante \u00e9 um recall alto para pneumonia. O modelo final tem um recall excelente, embora o desej\u00e1vel neste caso seja 100%, n\u00e3o sabemos se h\u00e1 erro de rotulagem nem qual o erro humano, muito menos o Bayes Error. Portanto, n\u00e3o d\u00e1 para saber se \u00e9 fact\u00edvel melhorar acima de 95-97% de recall. N\u00e3o foi poss\u00edvel obter ganhos significativos em rela\u00e7\u00e3o ao baseline com as t\u00e9cnicas empregadas. A melhoria foi marginal, de menos de 5% em rela\u00e7\u00e3o \u00e0 rede neural simples. Tabela abaixo. REDE 01b Accuracy: acc 0.95 val_acc 0.85 recall pneumonia: 0.94 0.95 REDE 02e Accuracy: acc 0.95 val_acc 0.89 recall pneumonia: 0.96 0.97 A diferen\u00e7a entre treinamento e valida\u00e7\u00e3o demonstra uma vari\u00e2ncia grande, mas pelos testes na base seria importante checar se n\u00e3o se trata de um data mismatch . Esta base parece ter problemas de balanceamento e tamb\u00e9m de distribui\u00e7\u00e3o. Como pr\u00f3ximo passo, seria interessante fundir todos os exemplos da base orginal (train, val, test) em uma base \u00fanica e fazer um resample das bases de treinamento e valida\u00e7\u00e3o, rodando c\u00f3pias destes notebooks e comparando os resultados. Al\u00e9m disso, testar t\u00e9cnicas adicionais de image augmentation e balanceamento de classes (par\u00e2metro class weight ou aumento de uma categoria).","title":"Observa\u00e7\u00f5es finais"},{"location":"notebooks_vazios/","text":"Relat\u00f3rios da BASE Vazios 01-Baseline-redesimples-vazio 01-Baseline-redesimples-vazio Rede convolucional bem simples treinada do zero. acc: 0.9551 - val_acc: 0.9564 Este notebook tamb\u00e9m cont\u00e9m visualiza\u00e7\u00f5es para tentar entender melhor o que foi aprendido pela rede. 01b-Baseline-redesimples-vazio-tamanhomaior 01b-Baseline-redesimples-vazio-tamanhomaior Mesma rede convolucional, mas treinada com entrada maior (224x224). O tamanho de entrada \u00e9 o mesmo da maioria dos modelos treinados na imagenet. acc: 0.9589 - val_acc: 0.9616 Em 26/06/2019: Rodada tr\u00eas vezes a sequ\u00eancia acima, 99, 101 e 103 erros de classifica\u00e7\u00e3o (a mudan\u00e7a \u00e9 devido a t\u00e9cnicas de image augmentation). Precis\u00e3o de 100% na classe 0 e recall 91% ou seja 9% de erros tipo II falso negativo (predi\u00e7\u00e3o 1 r\u00f3tulo 0). Analisando visualmente o diret\u00f3rio, pelo menos 25% dos erros s\u00e3o de rotulagem (os cont\u00eaineres realmente n\u00e3o cont\u00e9m carga. Dos 70-75 erros restantes, em 20% do total o cont\u00eainer est\u00e1 escuro, parecendo ter carga de espuma. Em torno de 30% do total tamb\u00e9m h\u00e1 diversos tipos de ru\u00eddos na imagem, desde carretas que invadem a \u00e1rea do cont\u00eainer at\u00e9 borr\u00f5es laterais na imagem, mas n\u00e3o carga. Ent\u00e3o tamb\u00e9m \u00e9 cont\u00eainer efetivamente vazio. Nos erros restantes (apenas 20% de 9%) parece haver erro de classifica\u00e7\u00e3o, mas o cont\u00eainer cont\u00e9m pouca carga. Conclus\u00f5es: * O erro real do algoritmo pode ser de apenas 2-4% e apenas na classe N\u00e3o Vazio. Este erro poderia ser melhorado com melhora no recorte do cont\u00eainer e na limpeza da imagem original. * Dos 9% de erros, 2% s\u00e3o aparentemente \"fraudes\": cont\u00eaineres n\u00e3o continham carga * Dos 9% de erros, 2% podem ser \"fraude\" ou falha no esc\u00e2ner * Necess\u00e1rio proibir carretas que obstruam o cont\u00eainer O algoritmo est\u00e1 tentendo a ignorar cargas de cont\u00eaineres declarados como vazios mas borrados/sujos ou com muito pouca carga ou com carga uniforme de espumas/materias pouco densos. Talvez fosse interessante for\u00e7ar o algoritmo a ser mais tendente a diminuir este erro, mesmo que isto custasse aumento de falso positivo na classe vazio. 01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered 01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Base aumentada: acc: 0.97 - val_acc: 0.97 Base original: acc: 0.96 - val_acc: 0.96 01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform 01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostransform Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Al\u00e9m disso, na inspe\u00e7\u00e3o visual do notebook 01b2 ficou a impress\u00e3o de que os erros que ainda estavam ocorrendo eram: erros que mesmo o humano teria dificuldade (cont\u00eaineres com espuma, por exemplo) ou erros de r\u00f3tulo persistentes. Al\u00e9m desses, o algoritmo ainda erra em alguns poucos casos de cont\u00eainer contendo muito pouca carga, especialmente se esta se concentra apenas no solo (provavelmente confunde com imagens de vazio com solo polu\u00eddo por carretas) ou somente em uma das portas (provavelmente confundindo com reefer). Assim, neste notebook foi diminu\u00edda a amplitude das transforma\u00e7\u00f5es de imagem aumentada para checar o resultado. Base aumentada: acc: 0.97 - val_acc: 0.98 Base original: acc: 0.96 - val_acc: 0.96 02-TransferLearningSimples-vazio 02-TransferLearningSimples-vazio Rede Densenet121, pr\u00e9 treinada na imagenet. acc: 0.9545 - val_acc: 0.7126 Claramente, houve um sobreajuste muito grande. Os erros de classifica\u00e7\u00e3o cometidos s\u00e3o gritantes. Foi realizado fine tunning do \u00faltimo bloco convolucional (conv5): acc: 0.9523 - val_acc: 0.8045 Apesar dos resultados ruins na generaliza\u00e7\u00e3o, necess\u00e1rio explorar mais esta possibilidade. A dificuldade pode ser devido ao bias em textura da imagenet. Note-se que esta base \u00e9 em tons de cinza, e o mais importante \u00e9 a geometria. Imagenet \u00e9 colorida e textura \u00e9 importante. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness https://arxiv.org/abs/1811.12231 02b-TransferLearningSimplesRegularizer-vazio 02b-TransferLearningSimplesRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. 02c-TransferLearning-FeatureExtractionRegularizer-vazio 02c-TransferLearningSimplesFeatureExtractionRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. acc: 0.9408 - val_acc: 0.9514 Neste caso, se optou por utilizar as camadas pr\u00e9 treinadas para feature extraction, e, foi utilizada Max Pooling na \u00faltima camada em vez de Avg Pooling. Observa\u00e7\u00f5es: Ap\u00f3s a extra\u00e7\u00e3o das features das imagens, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, a extra\u00e7\u00e3o separada dos features permitir\u00e1 treinar v\u00e1rios classificadores, fazer grid search e cross validation, entre outros. Conforme demonstrado acima, h\u00e1 entre as imagens da classe nvazio diversos exemplos que parecem da classe vazio. Ou s\u00e3o erros de base ou s\u00e3o exemplos extremamente similares aos vazios. O aprendizado deve melhorar eliminando estes da base. Ser\u00e1 criada uma c\u00f3pia da base sem esses exemplos, para testar os mesmos algoritmos e comparar. 02c2-TransferLearningFeatureExtraction-Vazio 02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" (teste 01b3) produzida por 02c e o2d2 Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Base original maxpool: acc: 0.9604 - val_acc: 0.9566 Base original avgpool: acc: 0.9594 - val_acc: 0.9588 Parece que n\u00e3o importa o que se tente, h\u00e1 um plat\u00f4 em torno de 0.96 para accuracy na base original. Com a base \"limpa\" de alguns erros de rotulagem, foi poss\u00edvel subir este plat\u00f4 para um pouco mais de 97%. Como a maioria dos erros \u00e9 na classe vazio, antes de prosseguir: * Testar neste mesmo notebook treinamento com class_weigth * Copiar este notebook e repetir mesmos passos na base gerada por 02d2 O uso de class_weight 3 para a classe 0 (n\u00e3o vazio) causou queda marginal na accuracy total, mas distribuindo melhor os erros, conforme tabela abaixo ( a accuracy caiu nas casas centesimais, em torno de 4 cent\u00e9simos): BASE TEST Sem class_weight precision recall f1-score support 0.0 0.99 0.92 0.96 1166 1.0 0.93 0.99 0.96 1138 Com class_weight precision recall f1-score support 0.0 0.97 0.94 0.95 1166 1.0 0.94 0.97 0.95 1138 BASE TRAIN Sem class_weight precision recall f1-score support 0.0 1.00 0.93 0.96 10494 1.0 0.93 1.00 0.96 10306 Com class_weight precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306 02c3-TransferLearningFeatureExtraction-Vazio 02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" e filtrado (mesma base que notebook 01b3) Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Detalhes no notebook. Resumindo, os resultados foram muito similares ao notebook 01b3: aumento de 2% em accuracy em rela\u00e7\u00e3o \u00e0 base original, provavelmente pela corre\u00e7\u00e3o de erros de r\u00f3tulo De resto, resultados similares ao notebook 02c2, em todas as tabelas (com o aumento de quase 2%) 02d-auxiliar-ImageAugmentation-Vazios 02d-auxiliar-ImageAugmentation-Vazios Notebook auxiliar para gerar uma base aumentada. 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es. 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios 02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es. 03-Busca-TransferLearning-Imagenet-Vazios.ipynb 03-Busca-TransferLearning-Imagenet-Vazios Teste do uso das features extra\u00eddas de uma rede pr\u00e9-treinada como hash para busca de similaridade. M\u00e9tricas utilizadas: Dos 10 primeiros e dos 20 primeiros resultados(de um total de 512), quantos pertencem \u00e0 mesma classe? Foram rodadas 1.000 simula\u00e7\u00f5es aleat\u00f3rias de busca para v\u00e1rios batchs diferentes, de 512 itens para base train e 256 itens para base. No final foram rodadas 1.000 simula\u00e7\u00f5es para 10 batches da base treinamento. A avalia\u00e7\u00e3o foi realizada por coincid\u00eancia de classe nos primeiros 10 e 20 itens e tamb\u00e9m foi realizada avalia\u00e7\u00e3o visual interativa. A avalia\u00e7\u00e3o visual demonstrou precis\u00e3o alta na compara\u00e7\u00e3o de vazios. Mas a compara\u00e7\u00e3o de cont\u00eaineres com Carga, imagem com mais informa\u00e7\u00e3o, pareceu bem mais prejudicada. A avalia\u00e7\u00e3o por classe deu uma coincid\u00eancia de pouco mais de 80%, considerada insuficiente. Tamb\u00e9m foi extra\u00edda a estat\u00edstica por classe: 0 = N\u00e3o vazio 1 = Vazio Resultados utilizando MaxPooling Acerto classe 0: 70719 de 99920 (0.71) Acerto classe 1: 85712 de 100080 (0.86) Resultados utilizando AvgPooling Acerto classe 0: 79105 de 107680 (0.73) Acerto classe 1: 83533 de 92320 (0.90) Assim, as features extra\u00eddas da rede treinada na ImageNet se mostraram insuficientes para busca. N\u00e3o obstante, podem ser um ponto de partida, para treinamento de autoencoders ou outras fun\u00e7\u00f5es para gerar um hash para busca de similaridade. Observa\u00e7\u00f5es Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpool nos resultados e menor tempo de converg\u00eancia. Os melhores resultados obtidos foram de 96% de accuracy e 96% de f1-score, sendo que a base parece ter em torno de 2% de erros de rotulagem. Com a base limpa, o resultado subiu a quase 98%. Embora pela visualiza\u00e7\u00e3o haja espa\u00e7o para melhora (alguns cont\u00eaineres n\u00e3o vazios com muito pouca carga mas facilmente identifi\u00e1veis pelo olho humano classificados como vazios), o modelo est\u00e1 muito pr\u00f3ximo de um candidato a coloca\u00e7\u00e3o em produ\u00e7\u00e3o. Outro ponto interessante \u00e9 que foi demostrado ser poss\u00edvel utilizar um classificador extremamente simples e r\u00e1pido, que utiliza como ponto de entrada apenas 1024 n\u00fameros que podem ser pr\u00e9-extra\u00eddos das imagens pela rede DenseNet121 e ocupa apenas 14MB de RAM por batch. precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306","title":"Relat\u00f3rio Vazios"},{"location":"notebooks_vazios/#relatorios-da-base-vazios","text":"","title":"Relat\u00f3rios da BASE Vazios"},{"location":"notebooks_vazios/#01-baseline-redesimples-vazio","text":"01-Baseline-redesimples-vazio Rede convolucional bem simples treinada do zero. acc: 0.9551 - val_acc: 0.9564 Este notebook tamb\u00e9m cont\u00e9m visualiza\u00e7\u00f5es para tentar entender melhor o que foi aprendido pela rede.","title":"01-Baseline-redesimples-vazio"},{"location":"notebooks_vazios/#01b-baseline-redesimples-vazio-tamanhomaior","text":"01b-Baseline-redesimples-vazio-tamanhomaior Mesma rede convolucional, mas treinada com entrada maior (224x224). O tamanho de entrada \u00e9 o mesmo da maioria dos modelos treinados na imagenet. acc: 0.9589 - val_acc: 0.9616 Em 26/06/2019: Rodada tr\u00eas vezes a sequ\u00eancia acima, 99, 101 e 103 erros de classifica\u00e7\u00e3o (a mudan\u00e7a \u00e9 devido a t\u00e9cnicas de image augmentation). Precis\u00e3o de 100% na classe 0 e recall 91% ou seja 9% de erros tipo II falso negativo (predi\u00e7\u00e3o 1 r\u00f3tulo 0). Analisando visualmente o diret\u00f3rio, pelo menos 25% dos erros s\u00e3o de rotulagem (os cont\u00eaineres realmente n\u00e3o cont\u00e9m carga. Dos 70-75 erros restantes, em 20% do total o cont\u00eainer est\u00e1 escuro, parecendo ter carga de espuma. Em torno de 30% do total tamb\u00e9m h\u00e1 diversos tipos de ru\u00eddos na imagem, desde carretas que invadem a \u00e1rea do cont\u00eainer at\u00e9 borr\u00f5es laterais na imagem, mas n\u00e3o carga. Ent\u00e3o tamb\u00e9m \u00e9 cont\u00eainer efetivamente vazio. Nos erros restantes (apenas 20% de 9%) parece haver erro de classifica\u00e7\u00e3o, mas o cont\u00eainer cont\u00e9m pouca carga. Conclus\u00f5es: * O erro real do algoritmo pode ser de apenas 2-4% e apenas na classe N\u00e3o Vazio. Este erro poderia ser melhorado com melhora no recorte do cont\u00eainer e na limpeza da imagem original. * Dos 9% de erros, 2% s\u00e3o aparentemente \"fraudes\": cont\u00eaineres n\u00e3o continham carga * Dos 9% de erros, 2% podem ser \"fraude\" ou falha no esc\u00e2ner * Necess\u00e1rio proibir carretas que obstruam o cont\u00eainer O algoritmo est\u00e1 tentendo a ignorar cargas de cont\u00eaineres declarados como vazios mas borrados/sujos ou com muito pouca carga ou com carga uniforme de espumas/materias pouco densos. Talvez fosse interessante for\u00e7ar o algoritmo a ser mais tendente a diminuir este erro, mesmo que isto custasse aumento de falso positivo na classe vazio.","title":"01b-Baseline-redesimples-vazio-tamanhomaior"},{"location":"notebooks_vazios/#01b2-baseline-redesimples-vazio-tamanhomaior-augmented-filtered","text":"01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Base aumentada: acc: 0.97 - val_acc: 0.97 Base original: acc: 0.96 - val_acc: 0.96","title":"01b2-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered"},{"location":"notebooks_vazios/#01b3-baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform","text":"01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostransform Este notebook aplica o mesmo m\u00e9todo que 01b, mas trocando para base aumentada e filtrada (redu\u00e7\u00e3o de erros de r\u00f3tulo) produzida por 02c e o2d2, isto \u00e9, foi gerada nova base, j\u00e1 aumentada e excluindo erros acima e abaixo de um threshold do classificador 02c, que na inspe\u00e7\u00e3o visual ficou evidente tratarem-se de erros de rotulagem, isto \u00e9, data mismatch. Al\u00e9m disso, na inspe\u00e7\u00e3o visual do notebook 01b2 ficou a impress\u00e3o de que os erros que ainda estavam ocorrendo eram: erros que mesmo o humano teria dificuldade (cont\u00eaineres com espuma, por exemplo) ou erros de r\u00f3tulo persistentes. Al\u00e9m desses, o algoritmo ainda erra em alguns poucos casos de cont\u00eainer contendo muito pouca carga, especialmente se esta se concentra apenas no solo (provavelmente confunde com imagens de vazio com solo polu\u00eddo por carretas) ou somente em uma das portas (provavelmente confundindo com reefer). Assim, neste notebook foi diminu\u00edda a amplitude das transforma\u00e7\u00f5es de imagem aumentada para checar o resultado. Base aumentada: acc: 0.97 - val_acc: 0.98 Base original: acc: 0.96 - val_acc: 0.96","title":"01b3-Baseline-redesimples-vazio-tamanhomaior-augmented-filtered-menostranform"},{"location":"notebooks_vazios/#02-transferlearningsimples-vazio","text":"02-TransferLearningSimples-vazio Rede Densenet121, pr\u00e9 treinada na imagenet. acc: 0.9545 - val_acc: 0.7126 Claramente, houve um sobreajuste muito grande. Os erros de classifica\u00e7\u00e3o cometidos s\u00e3o gritantes. Foi realizado fine tunning do \u00faltimo bloco convolucional (conv5): acc: 0.9523 - val_acc: 0.8045 Apesar dos resultados ruins na generaliza\u00e7\u00e3o, necess\u00e1rio explorar mais esta possibilidade. A dificuldade pode ser devido ao bias em textura da imagenet. Note-se que esta base \u00e9 em tons de cinza, e o mais importante \u00e9 a geometria. Imagenet \u00e9 colorida e textura \u00e9 importante. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness https://arxiv.org/abs/1811.12231","title":"02-TransferLearningSimples-vazio"},{"location":"notebooks_vazios/#02b-transferlearningsimplesregularizer-vazio","text":"02b-TransferLearningSimplesRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o.","title":"02b-TransferLearningSimplesRegularizer-vazio"},{"location":"notebooks_vazios/#02c-transferlearning-featureextractionregularizer-vazio","text":"02c-TransferLearningSimplesFeatureExtractionRegularizer-vazio Rede Densenet121, pr\u00e9 treinada na imagenet, com regulariza\u00e7\u00e3o. acc: 0.9408 - val_acc: 0.9514 Neste caso, se optou por utilizar as camadas pr\u00e9 treinadas para feature extraction, e, foi utilizada Max Pooling na \u00faltima camada em vez de Avg Pooling. Observa\u00e7\u00f5es: Ap\u00f3s a extra\u00e7\u00e3o das features das imagens, o treinamento do classificador \u00e9 centenas de vezes mais r\u00e1pido. Assim, a extra\u00e7\u00e3o separada dos features permitir\u00e1 treinar v\u00e1rios classificadores, fazer grid search e cross validation, entre outros. Conforme demonstrado acima, h\u00e1 entre as imagens da classe nvazio diversos exemplos que parecem da classe vazio. Ou s\u00e3o erros de base ou s\u00e3o exemplos extremamente similares aos vazios. O aprendizado deve melhorar eliminando estes da base. Ser\u00e1 criada uma c\u00f3pia da base sem esses exemplos, para testar os mesmos algoritmos e comparar.","title":"02c-TransferLearning-FeatureExtractionRegularizer-vazio"},{"location":"notebooks_vazios/#02c2-transferlearningfeatureextraction-vazio","text":"02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" (teste 01b3) produzida por 02c e o2d2 Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Base original maxpool: acc: 0.9604 - val_acc: 0.9566 Base original avgpool: acc: 0.9594 - val_acc: 0.9588 Parece que n\u00e3o importa o que se tente, h\u00e1 um plat\u00f4 em torno de 0.96 para accuracy na base original. Com a base \"limpa\" de alguns erros de rotulagem, foi poss\u00edvel subir este plat\u00f4 para um pouco mais de 97%. Como a maioria dos erros \u00e9 na classe vazio, antes de prosseguir: * Testar neste mesmo notebook treinamento com class_weigth * Copiar este notebook e repetir mesmos passos na base gerada por 02d2 O uso de class_weight 3 para a classe 0 (n\u00e3o vazio) causou queda marginal na accuracy total, mas distribuindo melhor os erros, conforme tabela abaixo ( a accuracy caiu nas casas centesimais, em torno de 4 cent\u00e9simos): BASE TEST Sem class_weight precision recall f1-score support 0.0 0.99 0.92 0.96 1166 1.0 0.93 0.99 0.96 1138 Com class_weight precision recall f1-score support 0.0 0.97 0.94 0.95 1166 1.0 0.94 0.97 0.95 1138 BASE TRAIN Sem class_weight precision recall f1-score support 0.0 1.00 0.93 0.96 10494 1.0 0.93 1.00 0.96 10306 Com class_weight precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306","title":"02c2-TransferLearningFeatureExtraction-Vazio"},{"location":"notebooks_vazios/#02c3-transferlearningfeatureextraction-vazio","text":"02c2-TransferLearningFeatureExtraction-Vazio Extrair features para numpy com imageaugmented bem \"suave\" e filtrado (mesma base que notebook 01b3) Rodar com maxpool e com avgpool para poder comparar Rodar keras_tuner e comparar resultados com melhor resultado da rede simples Detalhes no notebook. Resumindo, os resultados foram muito similares ao notebook 01b3: aumento de 2% em accuracy em rela\u00e7\u00e3o \u00e0 base original, provavelmente pela corre\u00e7\u00e3o de erros de r\u00f3tulo De resto, resultados similares ao notebook 02c2, em todas as tabelas (com o aumento de quase 2%)","title":"02c3-TransferLearningFeatureExtraction-Vazio"},{"location":"notebooks_vazios/#02d-auxiliar-imageaugmentation-vazios","text":"02d-auxiliar-ImageAugmentation-Vazios Notebook auxiliar para gerar uma base aumentada.","title":"02d-auxiliar-ImageAugmentation-Vazios"},{"location":"notebooks_vazios/#02d2-auxiliar-imageaugmentationmenostransfom-vazios","text":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es.","title":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios"},{"location":"notebooks_vazios/#02d2-auxiliar-imageaugmentationmenostransfom-vazios_1","text":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios Notebook auxiliar para gerar uma base aumentada com poucas transforma\u00e7\u00f5es.","title":"02d2-auxiliar-ImageAugmentationMenosTransfom-Vazios"},{"location":"notebooks_vazios/#03-busca-transferlearning-imagenet-vaziosipynb","text":"03-Busca-TransferLearning-Imagenet-Vazios Teste do uso das features extra\u00eddas de uma rede pr\u00e9-treinada como hash para busca de similaridade. M\u00e9tricas utilizadas: Dos 10 primeiros e dos 20 primeiros resultados(de um total de 512), quantos pertencem \u00e0 mesma classe? Foram rodadas 1.000 simula\u00e7\u00f5es aleat\u00f3rias de busca para v\u00e1rios batchs diferentes, de 512 itens para base train e 256 itens para base. No final foram rodadas 1.000 simula\u00e7\u00f5es para 10 batches da base treinamento. A avalia\u00e7\u00e3o foi realizada por coincid\u00eancia de classe nos primeiros 10 e 20 itens e tamb\u00e9m foi realizada avalia\u00e7\u00e3o visual interativa. A avalia\u00e7\u00e3o visual demonstrou precis\u00e3o alta na compara\u00e7\u00e3o de vazios. Mas a compara\u00e7\u00e3o de cont\u00eaineres com Carga, imagem com mais informa\u00e7\u00e3o, pareceu bem mais prejudicada. A avalia\u00e7\u00e3o por classe deu uma coincid\u00eancia de pouco mais de 80%, considerada insuficiente. Tamb\u00e9m foi extra\u00edda a estat\u00edstica por classe: 0 = N\u00e3o vazio 1 = Vazio Resultados utilizando MaxPooling Acerto classe 0: 70719 de 99920 (0.71) Acerto classe 1: 85712 de 100080 (0.86) Resultados utilizando AvgPooling Acerto classe 0: 79105 de 107680 (0.73) Acerto classe 1: 83533 de 92320 (0.90) Assim, as features extra\u00eddas da rede treinada na ImageNet se mostraram insuficientes para busca. N\u00e3o obstante, podem ser um ponto de partida, para treinamento de autoencoders ou outras fun\u00e7\u00f5es para gerar um hash para busca de similaridade.","title":"03-Busca-TransferLearning-Imagenet-Vazios.ipynb"},{"location":"notebooks_vazios/#observacoes","text":"Os resultados da rede simples treinada do zero foram similares ao uso de rede DenseNet, mas a extra\u00e7\u00e3o de features com rede pr\u00e9 treinada na imagenet pode ser um m\u00e9todo universal base para v\u00e1rios classificadores, buscas e an\u00e1lises. Assim, quando uma imagem entrar no Banco de Dados, pr\u00e9 extrair as features via uma rede pr\u00e9 treinada, salvando no Banco de Dados, pode servir como ponto de entrada para v\u00e1rios tipos de classificadores e compara\u00e7\u00f5es, salvando mem\u00f3ria e processamento posterior. Os resultados utilizando maxpool e avgpool como extrator de caracter\u00edsticas foram muito similares, com leve vantagem para avgpool nos resultados e menor tempo de converg\u00eancia. Os melhores resultados obtidos foram de 96% de accuracy e 96% de f1-score, sendo que a base parece ter em torno de 2% de erros de rotulagem. Com a base limpa, o resultado subiu a quase 98%. Embora pela visualiza\u00e7\u00e3o haja espa\u00e7o para melhora (alguns cont\u00eaineres n\u00e3o vazios com muito pouca carga mas facilmente identifi\u00e1veis pelo olho humano classificados como vazios), o modelo est\u00e1 muito pr\u00f3ximo de um candidato a coloca\u00e7\u00e3o em produ\u00e7\u00e3o. Outro ponto interessante \u00e9 que foi demostrado ser poss\u00edvel utilizar um classificador extremamente simples e r\u00e1pido, que utiliza como ponto de entrada apenas 1024 n\u00fameros que podem ser pr\u00e9-extra\u00eddos das imagens pela rede DenseNet121 e ocupa apenas 14MB de RAM por batch. precision recall f1-score support 0.0 0.98 0.95 0.96 10494 1.0 0.95 0.98 0.96 10306","title":"Observa\u00e7\u00f5es"},{"location":"resumo/","text":"Explora\u00e7\u00e3o BASE ChestXRay A base chestXRay \u00e9 composta de 5216 imagens na base de treinamento e 624 imagens na base teste. S\u00e3o imagens de raio X de t\u00f3rax, rotulados como paciente NORMAL e paciente com PNEUMONIA. A base \u00e9 levemente desbalanceada, havendo quase 3 vezes mais exemplos de pneumonia. BASE Vazios Esta base \u00e9 composta por 20845 imagens de treinamento e 2317 imagens de valida\u00e7\u00e3o. A base \u00e9 balanceada. S\u00e3o duas categorias: nvazio - cont\u00eaineres contendo algum tipo de carga, mesmo que m\u00ednimo, e vazio - cont\u00eaineres vazios. Foram inseridos propositalmente, somando \u00e0 extra\u00e7\u00e3o aleat\u00f3ria, 3000 imagens de cont\u00eaineres de \"classifica\u00e7\u00e3o dif\u00edcil\", imagens que algoritmos anteriores falharam para classificar. Al\u00e9m disso, durante a explora\u00e7\u00e3o, foram descobertas em torno de 2,5% de imagens rotuladas erradamente e 2% de imagens que mesmo a vis\u00e3o humana teria dificuldade de saber se est\u00e1 vazio ou n\u00e3o. Assim, como o melhor desempenho obtido foi pr\u00f3ximo de 98% para base \"limpa\" e de 96% para base completa (ver detalhes no relat\u00f3rio detalhado e nos respectivos notebooks) pode ser considerado que para esta tarefa foi obtido um classificador excelente. BASE NCMs \u00fanicos Esta base \u00e9 composta de 41809 imagens de 868 categorias. S\u00e3o imagens de inspe\u00e7\u00e3o n\u00e3o invasiva de cont\u00eaineres. Benchmark O primeiro modelo a ser treinado ser\u00e1 sempre uma rede convolucional bem simples. Al\u00e9m disso, na base Vazios, h\u00e1 um modelo em produ\u00e7\u00e3o, uma SVM, que poder\u00e1 ser comparada. As redes neurais convolucionais s\u00e3o hoje o \"estado da arte\" em vis\u00e3o computacional. As camadas convolucionais aprendem a aplicar filtros em diversas regi\u00f5es das imagens, destacando formas, texturas, linhas, de acordo com a necessidade da tarefa em que est\u00e3o sendo treinadas. As convolu\u00e7\u00f5es s\u00e3o aplicadas consecutivamente, em objetos cada vez maiores, porque as imagens s\u00e3o progressivamente filtradas por convulu\u00e7\u00f5es, ou mais comumente por camadas de pooling que diminuem o tamanho da entrada, destacando partes mais importantes, e os filtros das convolu\u00e7\u00f5es mais profundas combinam ent\u00e3o os destaques dos filtros predecessores. Nas \u00faltimas camadas, estes mapas de caracter\u00edsticas descobertos pelas convolu\u00e7\u00f5es s\u00e3o combinados em uma rede neural convencional conectada para utiliza\u00e7\u00e3o na tarefa de classifica\u00e7\u00e3o. Como a rede neural \u00e9 um aproximador de fun\u00e7\u00f5es universal, atrav\u00e9s de backpropagation e gradiente descendente esta consegue derivar os pesos necess\u00e1rios para a tarefa de classifica\u00e7\u00e3o treinada, desde que adequada projetada e treinada. Antes do advento das redes neurais, os algoritmos que costumavam obter melhores resultados em classifica\u00e7\u00e3o de imagens eram as Suport Vector Machines - SVMs. As SVMs podem utilizar diversos \"kernels\" para a tarefa de classifica\u00e7\u00e3o, tendo sido o kernel RBF utilizado com sucesso durante d\u00e9cadas, antes da rede AlexNet ter baixado em mais de 10 pontos percentuais o erro no desafio AlexNet, antes dominado por SVMs. O kernel rbf funciona procurando v\u00e1rias fun\u00e7\u00f5es gaussianas, em cada dimens\u00e3o, que separem por uma margem espec\u00edfica, que \u00e9 um hiperpar\u00e2metro do kernel, a maior quantidade de exemplos das classes. Assim, os baselines utilizados ser\u00e3o um kernel RBF j\u00e1 em produ\u00e7\u00e3o e uma rede neural extremamente simples e r\u00e1pida para treinar. Em seguida, ser\u00e1 utilizada a rede DenseNet121 que apresenta um bom equil\u00edbrio entre resultados comprovados em bases dif\u00edceis, consumo de mem\u00f3ria e complexidade computacional, com a t\u00e9cnica de Transfer Learning . Em seguida, ser\u00e1 treinado um modelo de rede siamesa. Todos os modelos ser\u00e3o avaliados paralelamente conforme se\u00e7\u00e3o m\u00e9tricas. Metodologia Pr\u00e9 processamento de dados Est\u00e1 sendo utilizado o pacote PIL ou o ImageDataGenerator(que usa pacote PIL) do keras para abertura das imagens e redimensionamento com ANTALIAS. Os valores RGB originais est\u00e3o sendo reescalados dividindo por 255. Al\u00e9m disso foram testadas diversas op\u00e7\u00f5es de Image Augmentation. No caso da base Vazios, foi detectado erro de rotulagem e automaticamente gerada uma base filtrada atrav\u00e9s de threshold em um dos classificadores treinados. Os detalhes do pr\u00e9 processamento e principalmente da execu\u00e7\u00e3o est\u00e3o nos Notebooks. Resumo/\u00edndice no pr\u00f3ximo item. An\u00e1lise Para obter melhores resultados, ser\u00e3o provavelmente necess\u00e1rias a utiliza\u00e7\u00e3o de t\u00e9cnicas adicionais, conforme citado anteriormente: Tranfer Learning: Consiste em utilizar pesos que representam conhecimento acumulado/aprendido por uma rede neural em dom\u00ednio similar. Assim, existem redes que s\u00e3o refer\u00eancias em papers publicados, representando avan\u00e7os tecnol\u00f3gicos, e que foram treinadas em milh\u00f5es de imagens, como na base ImageNet (http://www.image-net.org/). Estas redes s\u00e3o treinadas por semanas, nestes milh\u00f5es de imagens, aprendendo a \"ver\" formas, linhas, texturas, etc. Atrav\u00e9s do uso das primeiras camadas destas redes, excluindo apenas as \u00faltimas, respons\u00e1veis pela classifica\u00e7\u00e3o, podemos extrair um resumo de todo esse aprendizado e transferir este conhecimento para uma nova tarefa. Image Augmentation: Como temos relativamente poucos exemplos, uma forma de melhorar o aprendizado e principalmente evitar sobreajuste \u00e9 aplicar pequenas modifica\u00e7\u00f5es aleat\u00f3riamente na base de treinamento. Assim, simulamos o treinamento com uma base maior. O keras possui diversas fun\u00e7\u00f5es j\u00e1 pr\u00e9 preparadas para conseguir realizar esta tarefa com facilidade (https://keras.io/preprocessing/image/). Podem ser aplicados zooms, recortes, mudan\u00e7a de brilho, espelhamento, pequenos deslocamentos laterais, entre outros. Deve se ter em mente o dom\u00ednio do problema, para n\u00e3o realizar tranforma\u00e7\u00f5es que prejudiquem o aprendizado. Por exemplo, se o objeto a ser detectado tem um tamanho ou posi\u00e7\u00e3o fixos, usar recorte ou zoom seria inadequado e mesmo os deslocamentos n\u00e3o podem ser grandes. Siamese networks: As redes siamesas s\u00e3o em tudo iguais \u00e0s redes convolucionais normais, exceto por uma particularidade: voc\u00ea sempre passa duas imagens pela mesma rede e no final compara as sa\u00eddas. Com isso, a rede aprende uma fun\u00e7\u00e3o de similaridade, podendo ser utilizada para reconhecer objetos que n\u00e3o estavam na base de treinamento, desde que perten\u00e7am ao mesmo dom\u00edno. Junto com as GANs, s\u00e3o um avan\u00e7o interesssante sobre as redes neurais convencionais, podendo ajudar a resolver a imensa fome por dados para treinamento. Mas, assim como as GANs, s\u00e3o um pouco mais dif\u00edceis de treinar e utilizar. Como aprendem uma fun\u00e7\u00e3o de similaridade, redes siamesas podem aprender um melhor embedding da imagem (os n\u00fameros que estar\u00e3o na \u00faltima camada e representam tudo que foi \"visto\" pelas camadas convolucionais) e podem ser utilizadas para buscas de similaridade, One Shot Learning, para lidar com classes desbalanceadas e at\u00e9 para fazer acompanhamento visual de objetos (object tracking). One Shot Learning Signature Verification Implementa\u00e7\u00e3o e refinamento Ver pr\u00f3ximo item, que resume os achados de cada notebook utilizado.","title":"An\u00e1lise"},{"location":"resumo/#exploracao","text":"","title":"Explora\u00e7\u00e3o"},{"location":"resumo/#base-chestxray","text":"A base chestXRay \u00e9 composta de 5216 imagens na base de treinamento e 624 imagens na base teste. S\u00e3o imagens de raio X de t\u00f3rax, rotulados como paciente NORMAL e paciente com PNEUMONIA. A base \u00e9 levemente desbalanceada, havendo quase 3 vezes mais exemplos de pneumonia.","title":"BASE ChestXRay"},{"location":"resumo/#base-vazios","text":"Esta base \u00e9 composta por 20845 imagens de treinamento e 2317 imagens de valida\u00e7\u00e3o. A base \u00e9 balanceada. S\u00e3o duas categorias: nvazio - cont\u00eaineres contendo algum tipo de carga, mesmo que m\u00ednimo, e vazio - cont\u00eaineres vazios. Foram inseridos propositalmente, somando \u00e0 extra\u00e7\u00e3o aleat\u00f3ria, 3000 imagens de cont\u00eaineres de \"classifica\u00e7\u00e3o dif\u00edcil\", imagens que algoritmos anteriores falharam para classificar. Al\u00e9m disso, durante a explora\u00e7\u00e3o, foram descobertas em torno de 2,5% de imagens rotuladas erradamente e 2% de imagens que mesmo a vis\u00e3o humana teria dificuldade de saber se est\u00e1 vazio ou n\u00e3o. Assim, como o melhor desempenho obtido foi pr\u00f3ximo de 98% para base \"limpa\" e de 96% para base completa (ver detalhes no relat\u00f3rio detalhado e nos respectivos notebooks) pode ser considerado que para esta tarefa foi obtido um classificador excelente.","title":"BASE Vazios"},{"location":"resumo/#base-ncms-unicos","text":"Esta base \u00e9 composta de 41809 imagens de 868 categorias. S\u00e3o imagens de inspe\u00e7\u00e3o n\u00e3o invasiva de cont\u00eaineres.","title":"BASE NCMs \u00fanicos"},{"location":"resumo/#benchmark","text":"O primeiro modelo a ser treinado ser\u00e1 sempre uma rede convolucional bem simples. Al\u00e9m disso, na base Vazios, h\u00e1 um modelo em produ\u00e7\u00e3o, uma SVM, que poder\u00e1 ser comparada. As redes neurais convolucionais s\u00e3o hoje o \"estado da arte\" em vis\u00e3o computacional. As camadas convolucionais aprendem a aplicar filtros em diversas regi\u00f5es das imagens, destacando formas, texturas, linhas, de acordo com a necessidade da tarefa em que est\u00e3o sendo treinadas. As convolu\u00e7\u00f5es s\u00e3o aplicadas consecutivamente, em objetos cada vez maiores, porque as imagens s\u00e3o progressivamente filtradas por convulu\u00e7\u00f5es, ou mais comumente por camadas de pooling que diminuem o tamanho da entrada, destacando partes mais importantes, e os filtros das convolu\u00e7\u00f5es mais profundas combinam ent\u00e3o os destaques dos filtros predecessores. Nas \u00faltimas camadas, estes mapas de caracter\u00edsticas descobertos pelas convolu\u00e7\u00f5es s\u00e3o combinados em uma rede neural convencional conectada para utiliza\u00e7\u00e3o na tarefa de classifica\u00e7\u00e3o. Como a rede neural \u00e9 um aproximador de fun\u00e7\u00f5es universal, atrav\u00e9s de backpropagation e gradiente descendente esta consegue derivar os pesos necess\u00e1rios para a tarefa de classifica\u00e7\u00e3o treinada, desde que adequada projetada e treinada. Antes do advento das redes neurais, os algoritmos que costumavam obter melhores resultados em classifica\u00e7\u00e3o de imagens eram as Suport Vector Machines - SVMs. As SVMs podem utilizar diversos \"kernels\" para a tarefa de classifica\u00e7\u00e3o, tendo sido o kernel RBF utilizado com sucesso durante d\u00e9cadas, antes da rede AlexNet ter baixado em mais de 10 pontos percentuais o erro no desafio AlexNet, antes dominado por SVMs. O kernel rbf funciona procurando v\u00e1rias fun\u00e7\u00f5es gaussianas, em cada dimens\u00e3o, que separem por uma margem espec\u00edfica, que \u00e9 um hiperpar\u00e2metro do kernel, a maior quantidade de exemplos das classes. Assim, os baselines utilizados ser\u00e3o um kernel RBF j\u00e1 em produ\u00e7\u00e3o e uma rede neural extremamente simples e r\u00e1pida para treinar. Em seguida, ser\u00e1 utilizada a rede DenseNet121 que apresenta um bom equil\u00edbrio entre resultados comprovados em bases dif\u00edceis, consumo de mem\u00f3ria e complexidade computacional, com a t\u00e9cnica de Transfer Learning . Em seguida, ser\u00e1 treinado um modelo de rede siamesa. Todos os modelos ser\u00e3o avaliados paralelamente conforme se\u00e7\u00e3o m\u00e9tricas.","title":"Benchmark"},{"location":"resumo/#metodologia","text":"","title":"Metodologia"},{"location":"resumo/#pre-processamento-de-dados","text":"Est\u00e1 sendo utilizado o pacote PIL ou o ImageDataGenerator(que usa pacote PIL) do keras para abertura das imagens e redimensionamento com ANTALIAS. Os valores RGB originais est\u00e3o sendo reescalados dividindo por 255. Al\u00e9m disso foram testadas diversas op\u00e7\u00f5es de Image Augmentation. No caso da base Vazios, foi detectado erro de rotulagem e automaticamente gerada uma base filtrada atrav\u00e9s de threshold em um dos classificadores treinados. Os detalhes do pr\u00e9 processamento e principalmente da execu\u00e7\u00e3o est\u00e3o nos Notebooks. Resumo/\u00edndice no pr\u00f3ximo item.","title":"Pr\u00e9 processamento de dados"},{"location":"resumo/#analise","text":"Para obter melhores resultados, ser\u00e3o provavelmente necess\u00e1rias a utiliza\u00e7\u00e3o de t\u00e9cnicas adicionais, conforme citado anteriormente: Tranfer Learning: Consiste em utilizar pesos que representam conhecimento acumulado/aprendido por uma rede neural em dom\u00ednio similar. Assim, existem redes que s\u00e3o refer\u00eancias em papers publicados, representando avan\u00e7os tecnol\u00f3gicos, e que foram treinadas em milh\u00f5es de imagens, como na base ImageNet (http://www.image-net.org/). Estas redes s\u00e3o treinadas por semanas, nestes milh\u00f5es de imagens, aprendendo a \"ver\" formas, linhas, texturas, etc. Atrav\u00e9s do uso das primeiras camadas destas redes, excluindo apenas as \u00faltimas, respons\u00e1veis pela classifica\u00e7\u00e3o, podemos extrair um resumo de todo esse aprendizado e transferir este conhecimento para uma nova tarefa. Image Augmentation: Como temos relativamente poucos exemplos, uma forma de melhorar o aprendizado e principalmente evitar sobreajuste \u00e9 aplicar pequenas modifica\u00e7\u00f5es aleat\u00f3riamente na base de treinamento. Assim, simulamos o treinamento com uma base maior. O keras possui diversas fun\u00e7\u00f5es j\u00e1 pr\u00e9 preparadas para conseguir realizar esta tarefa com facilidade (https://keras.io/preprocessing/image/). Podem ser aplicados zooms, recortes, mudan\u00e7a de brilho, espelhamento, pequenos deslocamentos laterais, entre outros. Deve se ter em mente o dom\u00ednio do problema, para n\u00e3o realizar tranforma\u00e7\u00f5es que prejudiquem o aprendizado. Por exemplo, se o objeto a ser detectado tem um tamanho ou posi\u00e7\u00e3o fixos, usar recorte ou zoom seria inadequado e mesmo os deslocamentos n\u00e3o podem ser grandes. Siamese networks: As redes siamesas s\u00e3o em tudo iguais \u00e0s redes convolucionais normais, exceto por uma particularidade: voc\u00ea sempre passa duas imagens pela mesma rede e no final compara as sa\u00eddas. Com isso, a rede aprende uma fun\u00e7\u00e3o de similaridade, podendo ser utilizada para reconhecer objetos que n\u00e3o estavam na base de treinamento, desde que perten\u00e7am ao mesmo dom\u00edno. Junto com as GANs, s\u00e3o um avan\u00e7o interesssante sobre as redes neurais convencionais, podendo ajudar a resolver a imensa fome por dados para treinamento. Mas, assim como as GANs, s\u00e3o um pouco mais dif\u00edceis de treinar e utilizar. Como aprendem uma fun\u00e7\u00e3o de similaridade, redes siamesas podem aprender um melhor embedding da imagem (os n\u00fameros que estar\u00e3o na \u00faltima camada e representam tudo que foi \"visto\" pelas camadas convolucionais) e podem ser utilizadas para buscas de similaridade, One Shot Learning, para lidar com classes desbalanceadas e at\u00e9 para fazer acompanhamento visual de objetos (object tracking). One Shot Learning Signature Verification","title":"An\u00e1lise"},{"location":"resumo/#implementacao-e-refinamento","text":"Ver pr\u00f3ximo item, que resume os achados de cada notebook utilizado.","title":"Implementa\u00e7\u00e3o e refinamento"},{"location":"sobre/","text":"Desenvolvido na RFB dentro do escopo do Sistema AJNA Ivan da Silva Bras\u00edlico C\u00f3digo Fonte no GitHub Apresentado como Capstone Project no curso de Engenheiro de Machine Learning, Udacity.","title":"Sobre"},{"location":"sobre/#desenvolvido-na-rfb-dentro-do-escopo-do-sistema-ajna","text":"Ivan da Silva Bras\u00edlico C\u00f3digo Fonte no GitHub Apresentado como Capstone Project no curso de Engenheiro de Machine Learning, Udacity.","title":"Desenvolvido na RFB dentro do escopo do Sistema AJNA"}]}