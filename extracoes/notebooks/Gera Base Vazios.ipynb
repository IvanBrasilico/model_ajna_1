{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:04:13.679971Z",
     "start_time": "2020-03-19T15:04:13.636892Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from PIL import Image\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils import mongodb\n",
    "from vazios_cheios import cursor_vazio_nvazio, extract_to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:04:13.696519Z",
     "start_time": "2020-03-19T15:04:13.681646Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists('vazios'):\n",
    "    shutil.rmtree('vazios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vazios database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:04:38.541815Z",
     "start_time": "2020-03-19T15:04:13.698295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 365)  - abortando...\n",
      "(600, 365)  - abortando...\n",
      "(600, 357)  - abortando...\n",
      "(25, 400)  - abortando...\n",
      "(14, 400)  - abortando...\n",
      "(600, 338)  - abortando...\n",
      "(600, 350)  - abortando...\n",
      "(600, 337)  - abortando...\n",
      "(600, 352)  - abortando...\n",
      "(600, 338)  - abortando...\n",
      "(600, 352)  - abortando...\n",
      "(600, 335)  - abortando...\n",
      "(600, 350)  - abortando...\n",
      "(512, 400)  - abortando...\n",
      "(538, 400)  - abortando...\n",
      "(600, 346)  - abortando...\n",
      "(600, 349)  - abortando...\n",
      "(600, 345)  - abortando...\n",
      "(600, 375)  - abortando...\n",
      "(600, 341)  - abortando...\n",
      "(600, 376)  - abortando...\n",
      "(600, 390)  - abortando...\n",
      "(600, 387)  - abortando...\n",
      "(600, 381)  - abortando...\n",
      "(600, 338)  - abortando...\n",
      "(600, 348)  - abortando...\n",
      "(600, 338)  - abortando...\n",
      "(600, 367)  - abortando...\n",
      "(600, 334)  - abortando...\n",
      "(600, 337)  - abortando...\n",
      "(600, 342)  - abortando...\n",
      "499 arquivos exportados...\n",
      "8.79 segundos para processar 499 registros\n",
      "(600, 353)  - abortando...\n",
      "(600, 357)  - abortando...\n",
      "(600, 343)  - abortando...\n",
      "(600, 358)  - abortando...\n",
      "(563, 400)  - abortando...\n",
      "(393, 400)  - abortando...\n",
      "(471, 400)  - abortando...\n",
      "(600, 338)  - abortando...\n",
      "(595, 400)  - abortando...\n",
      "(600, 363)  - abortando...\n",
      "(498, 400)  - abortando...\n",
      "(514, 400)  - abortando...\n",
      "(600, 366)  - abortando...\n",
      "(463, 400)  - abortando...\n",
      "(501, 400)  - abortando...\n",
      "(600, 340)  - abortando...\n",
      "(600, 352)  - abortando...\n",
      "(600, 372)  - abortando...\n",
      "(600, 340)  - abortando...\n",
      "499 arquivos exportados...\n",
      "15.64 segundos para processar 499 registros\n"
     ]
    }
   ],
   "source": [
    "start = datetime(2017, 7, 1)\n",
    "end = datetime.today()\n",
    "limit = 500\n",
    "for label in (True, False):\n",
    "    s0 = time.time()\n",
    "    cursor = cursor_vazio_nvazio(mongodb, start, end, limit, label)\n",
    "    count = extract_to(cursor)\n",
    "    s1 = time.time()\n",
    "    print('{:0.2f} segundos para processar {:d} registros'.format((s1 - s0), count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Training a very basic convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:04:40.028748Z",
     "start_time": "2020-03-19T15:04:38.544338Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:04:40.336624Z",
     "start_time": "2020-03-19T15:04:40.030150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 144, 144, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 72, 72, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 72, 72, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 36, 36, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         65792     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,114,081\n",
      "Trainable params: 2,114,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "  layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                padding='same',\n",
    "                input_shape=(144, 144, 3)),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(128, (1, 1), activation='relu'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(256, (1, 1), activation='relu'),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    " \n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:08:04.486542Z",
     "start_time": "2020-03-19T15:08:04.265267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 761 images belonging to 2 classes.\n",
      "Found 189 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'vazios',\n",
    "    target_size=(144, 144),\n",
    "    batch_size=100,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'vazios',\n",
    "    target_size=(144, 144),\n",
    "    batch_size=50,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T15:17:45.610796Z",
     "start_time": "2020-03-19T15:08:14.977513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2218 - acc: 0.9396 - val_loss: 0.6177 - val_acc: 0.5400\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3893 - acc: 0.8121 - val_loss: 0.5396 - val_acc: 0.5400\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2903 - acc: 0.8804 - val_loss: 0.4787 - val_acc: 0.5400\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2307 - acc: 0.9225 - val_loss: 0.3939 - val_acc: 0.8200\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2920 - acc: 0.8922 - val_loss: 0.4050 - val_acc: 0.9800\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1969 - acc: 0.9501 - val_loss: 0.4409 - val_acc: 0.7400\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.3100 - acc: 0.8962 - val_loss: 0.4696 - val_acc: 0.5800\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1685 - acc: 0.9606 - val_loss: 0.5282 - val_acc: 0.5400\n",
      "Epoch 9/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.2204 - acc: 0.9183\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2091 - acc: 0.9251 - val_loss: 0.4244 - val_acc: 0.9800\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1211 - acc: 0.9632 - val_loss: 0.4304 - val_acc: 0.9000\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0983 - acc: 0.9737 - val_loss: 0.4115 - val_acc: 0.8200\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1083 - acc: 0.9724 - val_loss: 0.4184 - val_acc: 0.7600\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0815 - acc: 0.9803 - val_loss: 0.4037 - val_acc: 0.9000\n",
      "Epoch 14/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0866 - acc: 0.9818\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0954 - acc: 0.9790 - val_loss: 0.4011 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0925 - acc: 0.9816 - val_loss: 0.3869 - val_acc: 0.9400\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0785 - acc: 0.9816 - val_loss: 0.3913 - val_acc: 0.9400\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0830 - acc: 0.9816 - val_loss: 0.4042 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0879 - acc: 0.9803 - val_loss: 0.4196 - val_acc: 0.8400\n",
      "Epoch 19/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0839 - acc: 0.9788\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0838 - acc: 0.9803 - val_loss: 0.4061 - val_acc: 0.9400\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0930 - acc: 0.9803 - val_loss: 0.3935 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0734 - acc: 0.9790 - val_loss: 0.4036 - val_acc: 0.9200\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0861 - acc: 0.9816 - val_loss: 0.3992 - val_acc: 0.9000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0823 - acc: 0.9855 - val_loss: 0.4039 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0989 - acc: 0.9728\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0897 - acc: 0.9763 - val_loss: 0.4065 - val_acc: 0.9200\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0749 - acc: 0.9829 - val_loss: 0.3884 - val_acc: 0.9400\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0723 - acc: 0.9855 - val_loss: 0.3977 - val_acc: 0.8800\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0758 - acc: 0.9816 - val_loss: 0.4026 - val_acc: 0.8800\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0803 - acc: 0.9842 - val_loss: 0.3839 - val_acc: 0.9400\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0702 - acc: 0.9816 - val_loss: 0.3901 - val_acc: 0.9800\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1003 - acc: 0.9816 - val_loss: 0.4036 - val_acc: 0.9200\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0796 - acc: 0.9790 - val_loss: 0.4089 - val_acc: 0.8800\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0867 - acc: 0.9803 - val_loss: 0.3965 - val_acc: 0.9400\n",
      "Epoch 33/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.1047 - acc: 0.9773\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0952 - acc: 0.9803 - val_loss: 0.4068 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0811 - acc: 0.9816 - val_loss: 0.4215 - val_acc: 0.8200\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0762 - acc: 0.9855 - val_loss: 0.3935 - val_acc: 0.8600\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0709 - acc: 0.9829 - val_loss: 0.4085 - val_acc: 0.9200\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0802 - acc: 0.9829 - val_loss: 0.3874 - val_acc: 0.9800\n",
      "Epoch 38/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0863 - acc: 0.9818\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0880 - acc: 0.9816 - val_loss: 0.3997 - val_acc: 0.8800\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0735 - acc: 0.9816 - val_loss: 0.4043 - val_acc: 0.9000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0716 - acc: 0.9829 - val_loss: 0.3919 - val_acc: 0.8800\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0845 - acc: 0.9829 - val_loss: 0.4005 - val_acc: 0.8600\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0846 - acc: 0.9803 - val_loss: 0.4010 - val_acc: 0.9400\n",
      "Epoch 43/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0801 - acc: 0.9818\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0807 - acc: 0.9829 - val_loss: 0.3980 - val_acc: 0.9200\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0810 - acc: 0.9842 - val_loss: 0.3922 - val_acc: 0.9000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0707 - acc: 0.9869 - val_loss: 0.4137 - val_acc: 0.9000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0872 - acc: 0.9790 - val_loss: 0.4020 - val_acc: 0.9200\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0830 - acc: 0.9816 - val_loss: 0.3955 - val_acc: 0.9400\n",
      "Epoch 48/50\n",
      "7/8 [=========================>....] - ETA: 1s - loss: 0.0789 - acc: 0.9814\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0713 - acc: 0.9829 - val_loss: 0.3972 - val_acc: 0.8800\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0783 - acc: 0.9855 - val_loss: 0.4115 - val_acc: 0.9000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0811 - acc: 0.9816 - val_loss: 0.3962 - val_acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5ec1d7d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
    "                              verbose=1, min_delta=1e-2, mode='min')\n",
    "\n",
    "model.fit_generator(train_generator, epochs=50,\n",
    "                    callbacks=[reduce_lr],\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = validation_generator.samples // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
