{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:20:58.252811Z",
     "start_time": "2020-03-20T19:20:58.209688Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from PIL import Image\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils import mongodb\n",
    "from ncm_unico import cursor_ncm_unico, extract_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vazios database\n",
    "\n",
    "#### Necessário acesso ao Servidor ajna.labin.rf08.srf (e habilitação no AJNA) ou acesso ao Servidor mongo.labin.rf08.srf (e senha do banco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T12:02:34.534089Z",
     "start_time": "2020-03-20T12:02:34.532314Z"
    }
   },
   "outputs": [],
   "source": [
    "#if os.path.exists('ncmsunicos_cropped'):\n",
    "#    shutil.rmtree('ncmsunicos_cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:22:53.766472Z",
     "start_time": "2020-03-20T11:22:32.122765Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime(2017, 7, 1)\n",
    "end = datetime.today()\n",
    "limit = 1000\n",
    "limitportipo = 20\n",
    "for label in (True, False):\n",
    "    s0 = time.time()\n",
    "    cursor = cursor_vazio_nvazio(mongodb, start, end, limit, label, crop=True)\n",
    "    count = extract_to(cursor, crop=True)\n",
    "    s1 = time.time()\n",
    "    print('{:0.2f} segundos para processar {:d} registros'.format((s1 - s0), count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar pré processadas para visualização e cópia\n",
    "\n",
    "#### Esta parte é para gerar arquivos em tamanho menor, possibilitando a cópia e compartilhamento (PenDrive, GoogleDrive, ReceitaDrive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:19:22.762378Z",
     "start_time": "2020-03-20T11:19:22.630Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('ncmsunicos_cropped'):\n",
    "    os.mkdir('ncmsunicos_cropped')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:19:22.763334Z",
     "start_time": "2020-03-20T11:19:22.633Z"
    }
   },
   "outputs": [],
   "source": [
    "for classe in ():\n",
    "    for i, batch in enumerate(train_datagen.flow_from_directory(\n",
    "        'ncmsunicos_cropped',\n",
    "        target_size=(144, 288),\n",
    "        batch_size=10, \n",
    "        save_to_dir = 'transformed_ncmsunicos_cropped/' + classe,\n",
    "        classes=[classe])):\n",
    "        if i > 40:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Training a very basic convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:22:22.482794Z",
     "start_time": "2020-03-20T19:22:13.505323Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:28:25.920565Z",
     "start_time": "2020-03-20T19:28:25.717480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 144, 288, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 72, 72, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 72, 72, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 13, 13, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 128)       16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 2, 2, 512)         131584    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 156)               80028     \n",
      "=================================================================\n",
      "Total params: 2,408,252\n",
      "Trainable params: 2,408,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "  layers.Conv2D(16, (5, 5), activation='relu',\n",
    "                padding='same',\n",
    "                input_shape=(144, 288, 3)),\n",
    "  layers.MaxPooling2D(pool_size=(2, 4)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(128, (1, 1), activation='relu'),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  layers.Conv2D(512, (1, 1), activation='relu'),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.Dropout(0.4),\n",
    "  layers.Dense(156, activation='softmax')\n",
    " \n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:28:26.988117Z",
     "start_time": "2020-03-20T19:28:26.667133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 images belonging to 156 classes.\n",
      "Found 81 images belonging to 156 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'ncmsunicos_cropped',\n",
    "    target_size=(144, 288),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'ncmsunicos_cropped',\n",
    "    target_size=(144, 288),\n",
    "    batch_size=60,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:34:04.399078Z",
     "start_time": "2020-03-20T19:28:32.026242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 5 steps, validate for 1 steps\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 8s 2s/step - loss: 5.0428 - acc: 0.0069 - val_loss: 5.0247 - val_acc: 0.0333\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.9768 - acc: 0.0330 - val_loss: 4.9150 - val_acc: 0.0333\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.8907 - acc: 0.0330 - val_loss: 4.8578 - val_acc: 0.0500\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.8057 - acc: 0.0365 - val_loss: 4.8012 - val_acc: 0.0667\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.7191 - acc: 0.0521 - val_loss: 4.6743 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.5979 - acc: 0.0538 - val_loss: 4.5767 - val_acc: 0.1333\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.5676 - acc: 0.0660 - val_loss: 4.6248 - val_acc: 0.1333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.4607 - acc: 0.0712 - val_loss: 4.4967 - val_acc: 0.1500\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.4288 - acc: 0.0764 - val_loss: 4.4234 - val_acc: 0.1333\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.3134 - acc: 0.0833 - val_loss: 4.3574 - val_acc: 0.1833\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.2845 - acc: 0.1215 - val_loss: 4.4048 - val_acc: 0.2000\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.2809 - acc: 0.0712 - val_loss: 4.4298 - val_acc: 0.1500\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.1992 - acc: 0.1007 - val_loss: 4.2501 - val_acc: 0.1667\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.1848 - acc: 0.1163 - val_loss: 4.2231 - val_acc: 0.1833\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.1484 - acc: 0.1215 - val_loss: 4.4580 - val_acc: 0.1667\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.1199 - acc: 0.1146 - val_loss: 4.3146 - val_acc: 0.2000\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.0907 - acc: 0.1094 - val_loss: 4.4146 - val_acc: 0.1333\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.0981 - acc: 0.1302 - val_loss: 4.3750 - val_acc: 0.1167\n",
      "Epoch 19/50\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 4.0221 - acc: 0.1362\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "5/5 [==============================] - 6s 1s/step - loss: 4.0439 - acc: 0.1302 - val_loss: 4.2740 - val_acc: 0.2333\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.9990 - acc: 0.1198 - val_loss: 4.2048 - val_acc: 0.2000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.9135 - acc: 0.1510 - val_loss: 4.2342 - val_acc: 0.1833\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8787 - acc: 0.1424 - val_loss: 4.2135 - val_acc: 0.1667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.9217 - acc: 0.1528 - val_loss: 4.1782 - val_acc: 0.1667\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8993 - acc: 0.1337 - val_loss: 4.2001 - val_acc: 0.1833\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8886 - acc: 0.1441 - val_loss: 4.1498 - val_acc: 0.2167\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8814 - acc: 0.1458 - val_loss: 4.1935 - val_acc: 0.1667\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8715 - acc: 0.1389 - val_loss: 4.2099 - val_acc: 0.1833\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8604 - acc: 0.1580 - val_loss: 4.1201 - val_acc: 0.1833\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8147 - acc: 0.1458 - val_loss: 4.1308 - val_acc: 0.2167\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8421 - acc: 0.1528 - val_loss: 4.0864 - val_acc: 0.2333\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8095 - acc: 0.1406 - val_loss: 4.1122 - val_acc: 0.1167\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8098 - acc: 0.1372 - val_loss: 4.0870 - val_acc: 0.2333\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8245 - acc: 0.1632 - val_loss: 4.1102 - val_acc: 0.1833\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7367 - acc: 0.1493 - val_loss: 4.1079 - val_acc: 0.1833\n",
      "Epoch 35/50\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 3.7738 - acc: 0.1451\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8113 - acc: 0.1441 - val_loss: 4.0846 - val_acc: 0.1833\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8749 - acc: 0.1250 - val_loss: 4.1169 - val_acc: 0.1500\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8151 - acc: 0.1510 - val_loss: 4.1370 - val_acc: 0.1667\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8003 - acc: 0.1528 - val_loss: 4.1109 - val_acc: 0.2000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.7971 - acc: 0.1580 - val_loss: 4.0736 - val_acc: 0.2000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.7808 - acc: 0.1615 - val_loss: 4.0991 - val_acc: 0.1500\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7669 - acc: 0.1562 - val_loss: 4.1242 - val_acc: 0.1833\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7659 - acc: 0.1424 - val_loss: 4.0713 - val_acc: 0.1833\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7777 - acc: 0.1632 - val_loss: 4.0643 - val_acc: 0.2333\n",
      "Epoch 44/50\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 3.7647 - acc: 0.1339\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7859 - acc: 0.1406 - val_loss: 4.0911 - val_acc: 0.2167\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.7554 - acc: 0.1684 - val_loss: 4.0960 - val_acc: 0.2000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8043 - acc: 0.1545 - val_loss: 4.0775 - val_acc: 0.2167\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.7776 - acc: 0.1406 - val_loss: 4.0939 - val_acc: 0.2333\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8273 - acc: 0.1545 - val_loss: 4.1133 - val_acc: 0.1667\n",
      "Epoch 49/50\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 3.7816 - acc: 0.1585\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "5/5 [==============================] - 6s 1s/step - loss: 3.8070 - acc: 0.1493 - val_loss: 4.0785 - val_acc: 0.2167\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.7793 - acc: 0.1597 - val_loss: 4.1153 - val_acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0941a68fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5,\n",
    "                              verbose=1, min_delta=1e-2, mode='min')\n",
    "\n",
    "model.fit(train_generator, epochs=50,\n",
    "                    callbacks=[reduce_lr],\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = validation_generator.samples // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:34:14.160406Z",
     "start_time": "2020-03-20T19:34:13.735718Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('gerabasesncmsunicos_cropped.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:25:46.180120Z",
     "start_time": "2020-03-20T19:23:32.774Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fine tunning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4,\n",
    "                          verbose=1, min_delta=1e-2, mode='min')\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.000001), loss='binary_crossentropy', metrics=['acc'])\n",
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:25:46.181417Z",
     "start_time": "2020-03-20T19:23:50.821Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, epochs=20,\n",
    "                    callbacks=[reduce_lr],\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = validation_generator.samples // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:49:19.623309Z",
     "start_time": "2020-03-20T11:49:19.591749Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('gerabasesncmsunicos_cropped_tunned.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
